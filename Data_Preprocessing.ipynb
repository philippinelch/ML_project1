{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('c:\\\\Users\\\\utilisateur\\\\Documents\\\\GitHub\\\\ML_Project1\\\\ML_project1')\n",
    "         \n",
    "import sys\n",
    "sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport pandas as pd\\n\\n# Load your large dataset\\nfile_path = 'dataset\\\\x_train.csv'\\ndf = pd.read_csv(file_path)\\n\\n# Define the number of rows you want in each smaller file\\nrows_per_file = 50000  # You can change this based on the file size\\n\\n# Split the dataset\\nfor i in range(0, len(df), rows_per_file):\\n    # Create a smaller dataset slice\\n    df_subset = df[i:i+rows_per_file]\\n    \\n    # Save this slice to a new CSV file\\n    output_file = f'small_dataset_part_{i//rows_per_file + 1}.csv'\\n    df_subset.to_csv(output_file, index=False)\\n    print(f'Created {output_file}')\\n\""
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "# Load your large dataset\n",
    "file_path = 'dataset\\\\x_train.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define the number of rows you want in each smaller file\n",
    "rows_per_file = 50000  # You can change this based on the file size\n",
    "\n",
    "# Split the dataset\n",
    "for i in range(0, len(df), rows_per_file):\n",
    "    # Create a smaller dataset slice\n",
    "    df_subset = df[i:i+rows_per_file]\n",
    "    \n",
    "    # Save this slice to a new CSV file\n",
    "    output_file = f'small_dataset_part_{i//rows_per_file + 1}.csv'\n",
    "    df_subset.to_csv(output_file, index=False)\n",
    "    print(f'Created {output_file}')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "file_path = 'dataset\\\\'\n",
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data(file_path)\n",
    "\n",
    "removal_log = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_missing_values = []\n",
    "removed_variance = []\n",
    "removed_correlation = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_and_print_removals(headers, removed_indices, step_name, reason):\n",
    "    \"\"\"\n",
    "    Logs and prints the features removed at each step.\n",
    "\n",
    "    Args:\n",
    "        headers (list): The list of feature names.\n",
    "        removed_indices (list): Indices of features that were removed at the current step.\n",
    "        step_name (str): The name of the step where the features were removed.\n",
    "        reason (str): The reason why the features were removed.\n",
    "    \"\"\"\n",
    "    removed_features = [headers[i] for i in removed_indices]\n",
    "    for feature in removed_features:\n",
    "        removal_log.append(f\"{feature} removed at {step_name}: {reason}\")\n",
    "\n",
    "    print(f\"\\nStep {step_name} - Reason: {reason}:\")\n",
    "    print(f\"Removed {len(removed_features)} features: {removed_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print kept/removed features after each step\n",
    "def print_feature_info(headers, kept_indices, step_name):\n",
    "    \"\"\"\n",
    "    Prints the number of features that were kept and removed after each step, \n",
    "    along with the respective feature names.\n",
    "\n",
    "    Args:\n",
    "        headers (list): The list of feature names.\n",
    "        kept_indices (list): Indices of features that were kept after the step.\n",
    "        step_name (str): The name of the step for which this information is printed.\n",
    "    \"\"\"\n",
    "    kept_features = [headers[i] for i in kept_indices]\n",
    "    removed_features = [headers[i] for i in range(len(headers)) if i not in kept_indices]\n",
    "    \n",
    "    print(f\"\\nStep {step_name}:\")\n",
    "    print(f\"Kept {len(kept_features)} features: {kept_features}\")\n",
    "    print(f\"Removed {len(removed_features)} features: {removed_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_headers(csv_file_path):\n",
    "    \"\"\"\n",
    "    This function extracts the headers (feature names) from the given CSV file.\n",
    "    \n",
    "    Args:\n",
    "        csv_file_path (str): Path to the CSV file from which to extract headers.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of headers (feature names), excluding the 'Id' column.\n",
    "    \"\"\"\n",
    "    with open(csv_file_path, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        headers = next(reader)  # Read the first row as headers\n",
    "    return headers[1:]  # Exclude the first column header as it is 'Id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract headers from x_train.csv\n",
    "x_train_headers = extract_headers(\"dataset\\\\x_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary features: 14\n",
      "Continuous features: 102\n",
      "Categorical features: 205\n",
      "Binary features: ['IYEAR', 'DISPCODE', 'PVTRESD1', 'CELLFON3', 'LADULT', 'CADULT', 'PVTRESD2', 'CSTATE', 'SEX', '_DRDXAR1', '_FRTRESP', '_VEGRESP', '_FRT16', '_VEG23']\n",
      "Continuous features: ['_STATE', 'FMONTH', 'IDATE', 'IMONTH', 'IDAY', 'SEQNO', '_PSU', 'NUMADULT', 'NUMMEN', 'NUMWOMEN', 'HHADULT', 'PHYSHLTH', 'MENTHLTH', 'POORHLTH', 'DIABAGE2', 'CHILDREN', 'WEIGHT2', 'HEIGHT3', 'ALCDAY5', 'AVEDRNK2', 'DRNK3GE5', 'MAXDRNKS', 'FRUITJU1', 'FRUIT1', 'FVBEANS', 'FVGREEN', 'FVORANG', 'VEGETAB1', 'EXRACT11', 'EXEROFT1', 'EXERHMM1', 'EXRACT21', 'EXEROFT2', 'EXERHMM2', 'STRENGTH', 'JOINPAIN', 'FLSHTMY2', 'IMFVPLAC', 'HIVTSTD3', 'WHRTST10', 'BLDSUGAR', 'FEETCHK2', 'DOCTDIAB', 'CHKHEMO3', 'FEETCHK', 'CRGVREL1', 'CRGVPRB1', 'LONGWTCH', 'ASTHMAGE', 'ASDRVIST', 'ASRCHKUP', 'ASACTLIM', 'SCNTWRK1', 'SCNTLWK1', 'ADPLEASR', 'ADDOWN', 'ADSLEEP', 'ADENERGY', 'ADEAT1', 'ADFAIL', 'ADTHINK', 'ADMOVE', '_STSTR', '_STRWT', '_RAWRAKE', '_WT2RAKE', '_CLLCPWT', '_DUALCOR', '_LLCPWT', '_AGEG5YR', '_AGE80', 'HTIN4', 'HTM4', 'WTKG3', '_BMI5', 'DROCDY3_', '_DRNKWEK', 'FTJUDA1_', 'FRUTDA1_', 'BEANDAY_', 'GRENDAY_', 'ORNGDAY_', 'VEGEDA1_', '_FRUTSUM', '_VEGESUM', 'METVL11_', 'METVL21_', 'MAXVO2_', 'FC60_', 'PADUR1_', 'PADUR2_', 'PAFREQ1_', 'PAFREQ2_', '_MINAC11', '_MINAC21', 'STRFREQ_', 'PAMIN11_', 'PAMIN21_', 'PA1MIN_', 'PAVIG11_', 'PAVIG21_', 'PA1VIGM_']\n",
      "Categorical features: ['CTELENUM', 'COLGHOUS', 'STATERES', 'CTELNUM1', 'CELLFON2', 'CCLGHOUS', 'LANDLINE', 'GENHLTH', 'HLTHPLN1', 'PERSDOC2', 'MEDCOST', 'CHECKUP1', 'BPHIGH4', 'BPMEDS', 'BLOODCHO', 'CHOLCHK', 'TOLDHI2', 'CVDSTRK3', 'ASTHMA3', 'ASTHNOW', 'CHCSCNCR', 'CHCOCNCR', 'CHCCOPD1', 'HAVARTH3', 'ADDEPEV2', 'CHCKIDNY', 'DIABETE3', 'MARITAL', 'EDUCA', 'RENTHOM1', 'NUMHHOL2', 'NUMPHON2', 'CPDEMO1', 'VETERAN3', 'EMPLOY1', 'INCOME2', 'INTERNET', 'PREGNANT', 'QLACTLM2', 'USEEQUIP', 'BLIND', 'DECIDE', 'DIFFWALK', 'DIFFDRES', 'DIFFALON', 'SMOKE100', 'SMOKDAY2', 'STOPSMK2', 'LASTSMK2', 'USENOW3', 'EXERANY2', 'LMTJOIN3', 'ARTHDIS2', 'ARTHSOCL', 'SEATBELT', 'FLUSHOT6', 'PNEUVAC3', 'HIVTST6', 'PDIABTST', 'PREDIAB1', 'INSULIN', 'EYEEXAM', 'DIABEYE', 'DIABEDU', 'CAREGIV1', 'CRGVLNG1', 'CRGVHRS1', 'CRGVPERS', 'CRGVHOUS', 'CRGVMST2', 'CRGVEXPT', 'VIDFCLT2', 'VIREDIF3', 'VIPRFVS2', 'VINOCRE2', 'VIEYEXM2', 'VIINSUR2', 'VICTRCT4', 'VIGLUMA2', 'VIMACDG2', 'CIMEMLOS', 'CDHOUSE', 'CDASSIST', 'CDHELP', 'CDSOCIAL', 'CDDISCUS', 'WTCHSALT', 'DRADVISE', 'ASATTACK', 'ASERVIST', 'ASYMPTOM', 'ASNOSLEP', 'ASTHMED3', 'ASINHALR', 'HAREHAB1', 'STREHAB1', 'CVDASPRN', 'ASPUNSAF', 'RLIVPAIN', 'RDUCHART', 'RDUCSTRK', 'ARTTODAY', 'ARTHWGT', 'ARTHEXER', 'ARTHEDU', 'TETANUS', 'HPVADVC2', 'HPVADSHT', 'SHINGLE2', 'HADMAM', 'HOWLONG', 'HADPAP2', 'LASTPAP2', 'HPVTEST', 'HPLSTTST', 'HADHYST2', 'PROFEXAM', 'LENGEXAM', 'BLDSTOOL', 'LSTBLDS3', 'HADSIGM3', 'HADSGCO1', 'LASTSIG3', 'PCPSAAD2', 'PCPSADI1', 'PCPSARE1', 'PSATEST1', 'PSATIME', 'PCPSARS1', 'PCPSADE1', 'PCDMDECN', 'SCNTMNY1', 'SCNTMEL1', 'SCNTPAID', 'SCNTLPAD', 'SXORIENT', 'TRNSGNDR', 'RCSGENDR', 'RCSRLTN2', 'CASTHDX2', 'CASTHNO2', 'EMTSUPRT', 'LSATISFY', 'MISTMNT', 'ADANXEV', 'QSTVER', 'QSTLANG', 'MSCODE', '_CHISPNC', '_CRACE1', '_CPRACE', '_DUALUSE', '_RFHLTH', '_HCVU651', '_RFHYPE5', '_CHOLCHK', '_RFCHOL', '_LTASTH1', '_CASTHM1', '_ASTHMS1', '_PRACE1', '_MRACE1', '_HISPANC', '_RACE', '_RACEG21', '_RACEGR3', '_RACE_G1', '_AGE65YR', '_AGE_G', '_BMI5CAT', '_RFBMI5', '_CHLDCNT', '_EDUCAG', '_INCOMG', '_SMOKER3', '_RFSMOK3', 'DRNKANY5', '_RFBING5', '_RFDRHV5', '_MISFRTN', '_MISVEGN', '_FRTLT1', '_VEGLT1', '_FRUITEX', '_VEGETEX', '_TOTINDA', 'ACTIN11_', 'ACTIN21_', 'PAMISS1_', '_PACAT1', '_PAINDX1', '_PA150R2', '_PA300R2', '_PA30021', '_PASTRNG', '_PAREC1', '_PASTAE1', '_LMTACT1', '_LMTWRK1', '_LMTSCL1', '_RFSEAT2', '_RFSEAT3', '_FLSHOT6', '_PNEUMO2', '_AIDTST3']\n"
     ]
    }
   ],
   "source": [
    "# Initialize counters and lists\n",
    "binary_count = 0\n",
    "continuous_count = 0\n",
    "categorical_count = 0\n",
    "\n",
    "binary_features = []\n",
    "continuous_features = []\n",
    "categorical_features = []\n",
    "\n",
    "# Threshold for distinguishing categorical from continuous\n",
    "categorical_threshold = 10\n",
    "\n",
    "# Analyze each feature column-wise\n",
    "for col_idx in range(x_train.shape[1]):\n",
    "    column_data = x_train[:, col_idx]\n",
    "    \n",
    "    # Remove missing or empty values to avoid counting them\n",
    "    column_data = column_data[~np.isnan(column_data)]  # Remove NaN values\n",
    "\n",
    "    # Get unique values\n",
    "    unique_values = np.unique(column_data)\n",
    "    unique_count = len(unique_values)\n",
    "\n",
    "    # Binary feature: 2 unique values\n",
    "    if unique_count == 2:\n",
    "        binary_count += 1\n",
    "        binary_features.append(x_train_headers[col_idx])\n",
    "    \n",
    "    # Continuous feature: more than categorical_threshold unique values\n",
    "    elif unique_count > categorical_threshold:\n",
    "        continuous_count += 1\n",
    "        continuous_features.append(x_train_headers[col_idx])\n",
    "    \n",
    "    # Categorical feature: 3-10 unique values (or another condition you define)\n",
    "    else:\n",
    "        categorical_count += 1\n",
    "        categorical_features.append(x_train_headers[col_idx])\n",
    "\n",
    "# Output the counts and the feature types\n",
    "print(f\"Binary features: {binary_count}\")\n",
    "print(f\"Continuous features: {continuous_count}\")\n",
    "print(f\"Categorical features: {categorical_count}\")\n",
    "\n",
    "# Optionally, display the lists of features by type\n",
    "print(\"Binary features:\", binary_features)\n",
    "print(\"Continuous features:\", continuous_features)\n",
    "print(\"Categorical features:\", categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : Remove missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 1: Remove Missing Values - Reason: Too many missing values:\n",
      "Removed 178 features: ['CTELENUM', 'PVTRESD1', 'COLGHOUS', 'STATERES', 'CELLFON3', 'LADULT', 'NUMADULT', 'NUMMEN', 'NUMWOMEN', 'CTELNUM1', 'CELLFON2', 'CADULT', 'PVTRESD2', 'CCLGHOUS', 'CSTATE', 'LANDLINE', 'HHADULT', 'POORHLTH', 'BPMEDS', 'ASTHNOW', 'DIABAGE2', 'NUMHHOL2', 'NUMPHON2', 'CPDEMO1', 'PREGNANT', 'SMOKDAY2', 'STOPSMK2', 'LASTSMK2', 'AVEDRNK2', 'DRNK3GE5', 'MAXDRNKS', 'EXRACT11', 'EXEROFT1', 'EXERHMM1', 'EXRACT21', 'EXEROFT2', 'EXERHMM2', 'LMTJOIN3', 'ARTHDIS2', 'ARTHSOCL', 'JOINPAIN', 'FLSHTMY2', 'IMFVPLAC', 'HIVTSTD3', 'WHRTST10', 'PDIABTST', 'PREDIAB1', 'INSULIN', 'BLDSUGAR', 'FEETCHK2', 'DOCTDIAB', 'CHKHEMO3', 'FEETCHK', 'EYEEXAM', 'DIABEYE', 'DIABEDU', 'CAREGIV1', 'CRGVREL1', 'CRGVLNG1', 'CRGVHRS1', 'CRGVPRB1', 'CRGVPERS', 'CRGVHOUS', 'CRGVMST2', 'CRGVEXPT', 'VIDFCLT2', 'VIREDIF3', 'VIPRFVS2', 'VINOCRE2', 'VIEYEXM2', 'VIINSUR2', 'VICTRCT4', 'VIGLUMA2', 'VIMACDG2', 'CIMEMLOS', 'CDHOUSE', 'CDASSIST', 'CDHELP', 'CDSOCIAL', 'CDDISCUS', 'WTCHSALT', 'LONGWTCH', 'DRADVISE', 'ASTHMAGE', 'ASATTACK', 'ASERVIST', 'ASDRVIST', 'ASRCHKUP', 'ASACTLIM', 'ASYMPTOM', 'ASNOSLEP', 'ASTHMED3', 'ASINHALR', 'HAREHAB1', 'STREHAB1', 'CVDASPRN', 'ASPUNSAF', 'RLIVPAIN', 'RDUCHART', 'RDUCSTRK', 'ARTTODAY', 'ARTHWGT', 'ARTHEXER', 'ARTHEDU', 'TETANUS', 'HPVADVC2', 'HPVADSHT', 'SHINGLE2', 'HADMAM', 'HOWLONG', 'HADPAP2', 'LASTPAP2', 'HPVTEST', 'HPLSTTST', 'HADHYST2', 'PROFEXAM', 'LENGEXAM', 'BLDSTOOL', 'LSTBLDS3', 'HADSIGM3', 'HADSGCO1', 'LASTSIG3', 'PCPSAAD2', 'PCPSADI1', 'PCPSARE1', 'PSATEST1', 'PSATIME', 'PCPSARS1', 'PCPSADE1', 'PCDMDECN', 'SCNTMNY1', 'SCNTMEL1', 'SCNTPAID', 'SCNTWRK1', 'SCNTLPAD', 'SCNTLWK1', 'SXORIENT', 'TRNSGNDR', 'RCSGENDR', 'RCSRLTN2', 'CASTHDX2', 'CASTHNO2', 'EMTSUPRT', 'LSATISFY', 'ADPLEASR', 'ADDOWN', 'ADSLEEP', 'ADENERGY', 'ADEAT1', 'ADFAIL', 'ADTHINK', 'ADMOVE', 'MISTMNT', 'ADANXEV', 'MSCODE', '_CHISPNC', '_CRACE1', '_CPRACE', '_CLLCPWT', '_DUALCOR', 'METVL11_', 'METVL21_', 'ACTIN11_', 'ACTIN21_', 'PADUR1_', 'PADUR2_', 'PAFREQ1_', 'PAFREQ2_', '_MINAC11', '_MINAC21', 'PAMIN11_', 'PAMIN21_', 'PA1MIN_', 'PAVIG11_', 'PAVIG21_', 'PA1VIGM_', '_FLSHOT6', '_PNEUMO2']\n"
     ]
    }
   ],
   "source": [
    "def remove_missing_values(headers, data, threshold=0.25):\n",
    "    \"\"\"\n",
    "    Removes features (columns) from the dataset that have more than the specified\n",
    "    percentage of missing values.\n",
    "\n",
    "    Args:\n",
    "        headers (list): The list of feature names.\n",
    "        data (np.array): The dataset (numpy array) with features as columns.\n",
    "        threshold (float): The maximum allowed percentage of missing values (default is 25%).\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - valid_columns (list): The indices of the features that were kept.\n",
    "            - filtered_data (np.array): The filtered dataset with only the valid columns.\n",
    "    \"\"\"\n",
    "    # Find the percentage of missing values for each column\n",
    "    missing_values = np.isnan(data).mean(axis=0)\n",
    "    valid_columns = np.where(missing_values <= threshold)[0]\n",
    "    removed_columns = np.where(missing_values > threshold)[0]\n",
    "\n",
    "    # Store the removed features\n",
    "    removed_features_names = [headers[i] for i in removed_columns]\n",
    "    removed_missing_values.extend(removed_features_names)\n",
    "    \n",
    "    # Log removed features\n",
    "    log_and_print_removals(headers, removed_columns, \"1: Remove Missing Values\", \"Too many missing values\")\n",
    "    \n",
    "    # Filter out the columns with too many missing values\n",
    "    filtered_data = data[:, valid_columns]\n",
    "    return valid_columns, filtered_data\n",
    "\n",
    "# Apply Step 1: Missing Values\n",
    "valid_columns, x_train = remove_missing_values(x_train_headers, x_train)\n",
    "x_train_headers = [x_train_headers[i] for i in valid_columns]  # Update headers after removing columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 : Variance Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2: Variance Thresholding - Reason: Low variance:\n",
      "Removed 2 features: ['_FRT16', '_VEG23']\n"
     ]
    }
   ],
   "source": [
    "def variance_thresholding(headers, data, threshold=0.01):\n",
    "    \"\"\"\n",
    "    Removes features that have variance below a specified threshold.\n",
    "\n",
    "    Args:\n",
    "        headers (list): The list of feature names.\n",
    "        data (np.array): The dataset (numpy array) with features as columns.\n",
    "        threshold (float): The minimum variance threshold (default is 1%).\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - valid_columns (list): The indices of the features that were kept.\n",
    "            - filtered_data (np.array): The filtered dataset with only the valid columns.\n",
    "    \"\"\"\n",
    "    # Compute variance for each column\n",
    "    variances = np.nanvar(data, axis=0)\n",
    "    valid_columns = np.where(variances >= threshold)[0]\n",
    "    removed_columns = np.where(variances < threshold)[0]\n",
    "\n",
    "    # Store the removed features\n",
    "    removed_features_names = [headers[i] for i in removed_columns]\n",
    "    removed_variance.extend(removed_features_names)\n",
    "    \n",
    "    # Log removed features\n",
    "    log_and_print_removals(headers, removed_columns, \"2: Variance Thresholding\", \"Low variance\")\n",
    "    \n",
    "    # Keep only columns with variance above the threshold\n",
    "    filtered_data = data[:, valid_columns]\n",
    "    return valid_columns, filtered_data\n",
    "\n",
    "# Apply Step 2: Variance Thresholding\n",
    "valid_columns, x_train = variance_thresholding(x_train_headers, x_train)\n",
    "x_train_headers = [x_train_headers[i] for i in valid_columns]  # Update headers after removing columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3: Correlation Analysis - Reason: Low or high correlation:\n",
      "Removed 90 features: ['_STATE', 'FMONTH', 'IDATE', 'IMONTH', 'IDAY', 'IYEAR', 'DISPCODE', 'MENTHLTH', 'HLTHPLN1', 'PERSDOC2', 'MEDCOST', 'ASTHMA3', 'ADDEPEV2', 'MARITAL', 'RENTHOM1', 'INCOME2', 'WEIGHT2', 'HEIGHT3', 'BLIND', 'DECIDE', 'USENOW3', 'FRUITJU1', 'FRUIT1', 'FVBEANS', 'FVGREEN', 'FVORANG', 'VEGETAB1', 'EXERANY2', 'SEATBELT', 'HIVTST6', 'QSTLANG', '_STSTR', '_STRWT', '_RAWRAKE', '_WT2RAKE', '_DUALUSE', '_LLCPWT', '_LTASTH1', '_CASTHM1', '_ASTHMS1', '_PRACE1', '_MRACE1', '_HISPANC', '_RACE', '_RACEG21', '_RACEGR3', '_RACE_G1', 'HTIN4', 'HTM4', '_RFBMI5', '_SMOKER3', '_RFSMOK3', 'DRNKANY5', 'DROCDY3_', '_RFBING5', '_DRNKWEK', '_RFDRHV5', 'FTJUDA1_', 'FRUTDA1_', 'BEANDAY_', 'GRENDAY_', 'ORNGDAY_', 'VEGEDA1_', '_MISFRTN', '_MISVEGN', '_FRTRESP', '_VEGRESP', '_FRUTSUM', '_VEGESUM', '_FRTLT1', '_VEGLT1', '_FRUITEX', '_VEGETEX', '_TOTINDA', 'MAXVO2_', 'FC60_', 'STRFREQ_', 'PAMISS1_', '_PACAT1', '_PAINDX1', '_PA150R2', '_PA300R2', '_PA30021', '_PASTRNG', '_PAREC1', '_PASTAE1', '_LMTWRK1', '_RFSEAT2', '_RFSEAT3', '_AIDTST3']\n"
     ]
    }
   ],
   "source": [
    "def correlation_analysis(headers, x_data, y_data, low_threshold=0.05, high_threshold=0.9):\n",
    "    \"\"\"\n",
    "    Removes features that have low correlation with the outcome variable (y_data),\n",
    "    or that are highly correlated with other features.\n",
    "\n",
    "    Args:\n",
    "        headers (list): The list of feature names.\n",
    "        x_data (np.array): The feature dataset (numpy array) with features as columns.\n",
    "        y_data (np.array): The outcome variable (labels) to correlate with.\n",
    "        low_threshold (float): Minimum Pearson correlation threshold (default is 0.05).\n",
    "        high_threshold (float): Maximum Pearson correlation threshold (default is 0.9).\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - valid_columns (list): The indices of the features that were kept.\n",
    "            - filtered_data (np.array): The filtered dataset with only the valid columns.\n",
    "    \"\"\"\n",
    "    valid_columns = []\n",
    "    removed_columns = []\n",
    "\n",
    "    # Ensure feature and outcome have the same non-NaN indices\n",
    "    for i in range(x_data.shape[1]):\n",
    "        feature = x_data[:, i]\n",
    "\n",
    "        # Create a mask where both feature and y_data are non-NaN\n",
    "        non_nan_mask = ~np.isnan(feature) & ~np.isnan(y_data)\n",
    "\n",
    "        # Apply mask to both feature and y_data\n",
    "        feature_clean = feature[non_nan_mask]\n",
    "        y_data_clean = y_data[non_nan_mask]\n",
    "\n",
    "        # Compute correlation if both feature_clean and y_data_clean have enough data\n",
    "        if len(feature_clean) > 1 and len(y_data_clean) > 1:\n",
    "            correlation = np.corrcoef(feature_clean, y_data_clean)[0, 1]\n",
    "\n",
    "            # Check if the correlation is within the desired range\n",
    "            if abs(correlation) >= low_threshold and abs(correlation) <= high_threshold:\n",
    "                valid_columns.append(i)\n",
    "            else:\n",
    "                removed_columns.append(i)\n",
    "        else:\n",
    "            removed_columns.append(i)\n",
    "\n",
    "    # Log removed features\n",
    "    log_and_print_removals(headers, removed_columns, \"3: Correlation Analysis\", \"Low or high correlation\")\n",
    "\n",
    "    # Store the removed features\n",
    "    removed_features_names = [headers[i] for i in removed_columns]\n",
    "    removed_correlation.extend(removed_features_names)\n",
    "\n",
    "    # Filter valid columns\n",
    "    filtered_data = x_data[:, valid_columns]\n",
    "    return valid_columns, filtered_data\n",
    "\n",
    "# Apply Step 3: Correlation Analysis\n",
    "valid_columns, x_train = correlation_analysis(x_train_headers, x_train, y_train)\n",
    "x_train_headers = [x_train_headers[i] for i in valid_columns]  # Update headers after removing columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removal Log:\n",
      "CTELENUM removed at 1: Remove Missing Values: Too many missing values\n",
      "PVTRESD1 removed at 1: Remove Missing Values: Too many missing values\n",
      "COLGHOUS removed at 1: Remove Missing Values: Too many missing values\n",
      "STATERES removed at 1: Remove Missing Values: Too many missing values\n",
      "CELLFON3 removed at 1: Remove Missing Values: Too many missing values\n",
      "LADULT removed at 1: Remove Missing Values: Too many missing values\n",
      "NUMADULT removed at 1: Remove Missing Values: Too many missing values\n",
      "NUMMEN removed at 1: Remove Missing Values: Too many missing values\n",
      "NUMWOMEN removed at 1: Remove Missing Values: Too many missing values\n",
      "CTELNUM1 removed at 1: Remove Missing Values: Too many missing values\n",
      "CELLFON2 removed at 1: Remove Missing Values: Too many missing values\n",
      "CADULT removed at 1: Remove Missing Values: Too many missing values\n",
      "PVTRESD2 removed at 1: Remove Missing Values: Too many missing values\n",
      "CCLGHOUS removed at 1: Remove Missing Values: Too many missing values\n",
      "CSTATE removed at 1: Remove Missing Values: Too many missing values\n",
      "LANDLINE removed at 1: Remove Missing Values: Too many missing values\n",
      "HHADULT removed at 1: Remove Missing Values: Too many missing values\n",
      "POORHLTH removed at 1: Remove Missing Values: Too many missing values\n",
      "BPMEDS removed at 1: Remove Missing Values: Too many missing values\n",
      "ASTHNOW removed at 1: Remove Missing Values: Too many missing values\n",
      "DIABAGE2 removed at 1: Remove Missing Values: Too many missing values\n",
      "NUMHHOL2 removed at 1: Remove Missing Values: Too many missing values\n",
      "NUMPHON2 removed at 1: Remove Missing Values: Too many missing values\n",
      "CPDEMO1 removed at 1: Remove Missing Values: Too many missing values\n",
      "PREGNANT removed at 1: Remove Missing Values: Too many missing values\n",
      "SMOKDAY2 removed at 1: Remove Missing Values: Too many missing values\n",
      "STOPSMK2 removed at 1: Remove Missing Values: Too many missing values\n",
      "LASTSMK2 removed at 1: Remove Missing Values: Too many missing values\n",
      "AVEDRNK2 removed at 1: Remove Missing Values: Too many missing values\n",
      "DRNK3GE5 removed at 1: Remove Missing Values: Too many missing values\n",
      "MAXDRNKS removed at 1: Remove Missing Values: Too many missing values\n",
      "EXRACT11 removed at 1: Remove Missing Values: Too many missing values\n",
      "EXEROFT1 removed at 1: Remove Missing Values: Too many missing values\n",
      "EXERHMM1 removed at 1: Remove Missing Values: Too many missing values\n",
      "EXRACT21 removed at 1: Remove Missing Values: Too many missing values\n",
      "EXEROFT2 removed at 1: Remove Missing Values: Too many missing values\n",
      "EXERHMM2 removed at 1: Remove Missing Values: Too many missing values\n",
      "LMTJOIN3 removed at 1: Remove Missing Values: Too many missing values\n",
      "ARTHDIS2 removed at 1: Remove Missing Values: Too many missing values\n",
      "ARTHSOCL removed at 1: Remove Missing Values: Too many missing values\n",
      "JOINPAIN removed at 1: Remove Missing Values: Too many missing values\n",
      "FLSHTMY2 removed at 1: Remove Missing Values: Too many missing values\n",
      "IMFVPLAC removed at 1: Remove Missing Values: Too many missing values\n",
      "HIVTSTD3 removed at 1: Remove Missing Values: Too many missing values\n",
      "WHRTST10 removed at 1: Remove Missing Values: Too many missing values\n",
      "PDIABTST removed at 1: Remove Missing Values: Too many missing values\n",
      "PREDIAB1 removed at 1: Remove Missing Values: Too many missing values\n",
      "INSULIN removed at 1: Remove Missing Values: Too many missing values\n",
      "BLDSUGAR removed at 1: Remove Missing Values: Too many missing values\n",
      "FEETCHK2 removed at 1: Remove Missing Values: Too many missing values\n",
      "DOCTDIAB removed at 1: Remove Missing Values: Too many missing values\n",
      "CHKHEMO3 removed at 1: Remove Missing Values: Too many missing values\n",
      "FEETCHK removed at 1: Remove Missing Values: Too many missing values\n",
      "EYEEXAM removed at 1: Remove Missing Values: Too many missing values\n",
      "DIABEYE removed at 1: Remove Missing Values: Too many missing values\n",
      "DIABEDU removed at 1: Remove Missing Values: Too many missing values\n",
      "CAREGIV1 removed at 1: Remove Missing Values: Too many missing values\n",
      "CRGVREL1 removed at 1: Remove Missing Values: Too many missing values\n",
      "CRGVLNG1 removed at 1: Remove Missing Values: Too many missing values\n",
      "CRGVHRS1 removed at 1: Remove Missing Values: Too many missing values\n",
      "CRGVPRB1 removed at 1: Remove Missing Values: Too many missing values\n",
      "CRGVPERS removed at 1: Remove Missing Values: Too many missing values\n",
      "CRGVHOUS removed at 1: Remove Missing Values: Too many missing values\n",
      "CRGVMST2 removed at 1: Remove Missing Values: Too many missing values\n",
      "CRGVEXPT removed at 1: Remove Missing Values: Too many missing values\n",
      "VIDFCLT2 removed at 1: Remove Missing Values: Too many missing values\n",
      "VIREDIF3 removed at 1: Remove Missing Values: Too many missing values\n",
      "VIPRFVS2 removed at 1: Remove Missing Values: Too many missing values\n",
      "VINOCRE2 removed at 1: Remove Missing Values: Too many missing values\n",
      "VIEYEXM2 removed at 1: Remove Missing Values: Too many missing values\n",
      "VIINSUR2 removed at 1: Remove Missing Values: Too many missing values\n",
      "VICTRCT4 removed at 1: Remove Missing Values: Too many missing values\n",
      "VIGLUMA2 removed at 1: Remove Missing Values: Too many missing values\n",
      "VIMACDG2 removed at 1: Remove Missing Values: Too many missing values\n",
      "CIMEMLOS removed at 1: Remove Missing Values: Too many missing values\n",
      "CDHOUSE removed at 1: Remove Missing Values: Too many missing values\n",
      "CDASSIST removed at 1: Remove Missing Values: Too many missing values\n",
      "CDHELP removed at 1: Remove Missing Values: Too many missing values\n",
      "CDSOCIAL removed at 1: Remove Missing Values: Too many missing values\n",
      "CDDISCUS removed at 1: Remove Missing Values: Too many missing values\n",
      "WTCHSALT removed at 1: Remove Missing Values: Too many missing values\n",
      "LONGWTCH removed at 1: Remove Missing Values: Too many missing values\n",
      "DRADVISE removed at 1: Remove Missing Values: Too many missing values\n",
      "ASTHMAGE removed at 1: Remove Missing Values: Too many missing values\n",
      "ASATTACK removed at 1: Remove Missing Values: Too many missing values\n",
      "ASERVIST removed at 1: Remove Missing Values: Too many missing values\n",
      "ASDRVIST removed at 1: Remove Missing Values: Too many missing values\n",
      "ASRCHKUP removed at 1: Remove Missing Values: Too many missing values\n",
      "ASACTLIM removed at 1: Remove Missing Values: Too many missing values\n",
      "ASYMPTOM removed at 1: Remove Missing Values: Too many missing values\n",
      "ASNOSLEP removed at 1: Remove Missing Values: Too many missing values\n",
      "ASTHMED3 removed at 1: Remove Missing Values: Too many missing values\n",
      "ASINHALR removed at 1: Remove Missing Values: Too many missing values\n",
      "HAREHAB1 removed at 1: Remove Missing Values: Too many missing values\n",
      "STREHAB1 removed at 1: Remove Missing Values: Too many missing values\n",
      "CVDASPRN removed at 1: Remove Missing Values: Too many missing values\n",
      "ASPUNSAF removed at 1: Remove Missing Values: Too many missing values\n",
      "RLIVPAIN removed at 1: Remove Missing Values: Too many missing values\n",
      "RDUCHART removed at 1: Remove Missing Values: Too many missing values\n",
      "RDUCSTRK removed at 1: Remove Missing Values: Too many missing values\n",
      "ARTTODAY removed at 1: Remove Missing Values: Too many missing values\n",
      "ARTHWGT removed at 1: Remove Missing Values: Too many missing values\n",
      "ARTHEXER removed at 1: Remove Missing Values: Too many missing values\n",
      "ARTHEDU removed at 1: Remove Missing Values: Too many missing values\n",
      "TETANUS removed at 1: Remove Missing Values: Too many missing values\n",
      "HPVADVC2 removed at 1: Remove Missing Values: Too many missing values\n",
      "HPVADSHT removed at 1: Remove Missing Values: Too many missing values\n",
      "SHINGLE2 removed at 1: Remove Missing Values: Too many missing values\n",
      "HADMAM removed at 1: Remove Missing Values: Too many missing values\n",
      "HOWLONG removed at 1: Remove Missing Values: Too many missing values\n",
      "HADPAP2 removed at 1: Remove Missing Values: Too many missing values\n",
      "LASTPAP2 removed at 1: Remove Missing Values: Too many missing values\n",
      "HPVTEST removed at 1: Remove Missing Values: Too many missing values\n",
      "HPLSTTST removed at 1: Remove Missing Values: Too many missing values\n",
      "HADHYST2 removed at 1: Remove Missing Values: Too many missing values\n",
      "PROFEXAM removed at 1: Remove Missing Values: Too many missing values\n",
      "LENGEXAM removed at 1: Remove Missing Values: Too many missing values\n",
      "BLDSTOOL removed at 1: Remove Missing Values: Too many missing values\n",
      "LSTBLDS3 removed at 1: Remove Missing Values: Too many missing values\n",
      "HADSIGM3 removed at 1: Remove Missing Values: Too many missing values\n",
      "HADSGCO1 removed at 1: Remove Missing Values: Too many missing values\n",
      "LASTSIG3 removed at 1: Remove Missing Values: Too many missing values\n",
      "PCPSAAD2 removed at 1: Remove Missing Values: Too many missing values\n",
      "PCPSADI1 removed at 1: Remove Missing Values: Too many missing values\n",
      "PCPSARE1 removed at 1: Remove Missing Values: Too many missing values\n",
      "PSATEST1 removed at 1: Remove Missing Values: Too many missing values\n",
      "PSATIME removed at 1: Remove Missing Values: Too many missing values\n",
      "PCPSARS1 removed at 1: Remove Missing Values: Too many missing values\n",
      "PCPSADE1 removed at 1: Remove Missing Values: Too many missing values\n",
      "PCDMDECN removed at 1: Remove Missing Values: Too many missing values\n",
      "SCNTMNY1 removed at 1: Remove Missing Values: Too many missing values\n",
      "SCNTMEL1 removed at 1: Remove Missing Values: Too many missing values\n",
      "SCNTPAID removed at 1: Remove Missing Values: Too many missing values\n",
      "SCNTWRK1 removed at 1: Remove Missing Values: Too many missing values\n",
      "SCNTLPAD removed at 1: Remove Missing Values: Too many missing values\n",
      "SCNTLWK1 removed at 1: Remove Missing Values: Too many missing values\n",
      "SXORIENT removed at 1: Remove Missing Values: Too many missing values\n",
      "TRNSGNDR removed at 1: Remove Missing Values: Too many missing values\n",
      "RCSGENDR removed at 1: Remove Missing Values: Too many missing values\n",
      "RCSRLTN2 removed at 1: Remove Missing Values: Too many missing values\n",
      "CASTHDX2 removed at 1: Remove Missing Values: Too many missing values\n",
      "CASTHNO2 removed at 1: Remove Missing Values: Too many missing values\n",
      "EMTSUPRT removed at 1: Remove Missing Values: Too many missing values\n",
      "LSATISFY removed at 1: Remove Missing Values: Too many missing values\n",
      "ADPLEASR removed at 1: Remove Missing Values: Too many missing values\n",
      "ADDOWN removed at 1: Remove Missing Values: Too many missing values\n",
      "ADSLEEP removed at 1: Remove Missing Values: Too many missing values\n",
      "ADENERGY removed at 1: Remove Missing Values: Too many missing values\n",
      "ADEAT1 removed at 1: Remove Missing Values: Too many missing values\n",
      "ADFAIL removed at 1: Remove Missing Values: Too many missing values\n",
      "ADTHINK removed at 1: Remove Missing Values: Too many missing values\n",
      "ADMOVE removed at 1: Remove Missing Values: Too many missing values\n",
      "MISTMNT removed at 1: Remove Missing Values: Too many missing values\n",
      "ADANXEV removed at 1: Remove Missing Values: Too many missing values\n",
      "MSCODE removed at 1: Remove Missing Values: Too many missing values\n",
      "_CHISPNC removed at 1: Remove Missing Values: Too many missing values\n",
      "_CRACE1 removed at 1: Remove Missing Values: Too many missing values\n",
      "_CPRACE removed at 1: Remove Missing Values: Too many missing values\n",
      "_CLLCPWT removed at 1: Remove Missing Values: Too many missing values\n",
      "_DUALCOR removed at 1: Remove Missing Values: Too many missing values\n",
      "METVL11_ removed at 1: Remove Missing Values: Too many missing values\n",
      "METVL21_ removed at 1: Remove Missing Values: Too many missing values\n",
      "ACTIN11_ removed at 1: Remove Missing Values: Too many missing values\n",
      "ACTIN21_ removed at 1: Remove Missing Values: Too many missing values\n",
      "PADUR1_ removed at 1: Remove Missing Values: Too many missing values\n",
      "PADUR2_ removed at 1: Remove Missing Values: Too many missing values\n",
      "PAFREQ1_ removed at 1: Remove Missing Values: Too many missing values\n",
      "PAFREQ2_ removed at 1: Remove Missing Values: Too many missing values\n",
      "_MINAC11 removed at 1: Remove Missing Values: Too many missing values\n",
      "_MINAC21 removed at 1: Remove Missing Values: Too many missing values\n",
      "PAMIN11_ removed at 1: Remove Missing Values: Too many missing values\n",
      "PAMIN21_ removed at 1: Remove Missing Values: Too many missing values\n",
      "PA1MIN_ removed at 1: Remove Missing Values: Too many missing values\n",
      "PAVIG11_ removed at 1: Remove Missing Values: Too many missing values\n",
      "PAVIG21_ removed at 1: Remove Missing Values: Too many missing values\n",
      "PA1VIGM_ removed at 1: Remove Missing Values: Too many missing values\n",
      "_FLSHOT6 removed at 1: Remove Missing Values: Too many missing values\n",
      "_PNEUMO2 removed at 1: Remove Missing Values: Too many missing values\n",
      "_FRT16 removed at 2: Variance Thresholding: Low variance\n",
      "_VEG23 removed at 2: Variance Thresholding: Low variance\n",
      "_STATE removed at 3: Correlation Analysis: Low or high correlation\n",
      "FMONTH removed at 3: Correlation Analysis: Low or high correlation\n",
      "IDATE removed at 3: Correlation Analysis: Low or high correlation\n",
      "IMONTH removed at 3: Correlation Analysis: Low or high correlation\n",
      "IDAY removed at 3: Correlation Analysis: Low or high correlation\n",
      "IYEAR removed at 3: Correlation Analysis: Low or high correlation\n",
      "DISPCODE removed at 3: Correlation Analysis: Low or high correlation\n",
      "MENTHLTH removed at 3: Correlation Analysis: Low or high correlation\n",
      "HLTHPLN1 removed at 3: Correlation Analysis: Low or high correlation\n",
      "PERSDOC2 removed at 3: Correlation Analysis: Low or high correlation\n",
      "MEDCOST removed at 3: Correlation Analysis: Low or high correlation\n",
      "ASTHMA3 removed at 3: Correlation Analysis: Low or high correlation\n",
      "ADDEPEV2 removed at 3: Correlation Analysis: Low or high correlation\n",
      "MARITAL removed at 3: Correlation Analysis: Low or high correlation\n",
      "RENTHOM1 removed at 3: Correlation Analysis: Low or high correlation\n",
      "INCOME2 removed at 3: Correlation Analysis: Low or high correlation\n",
      "WEIGHT2 removed at 3: Correlation Analysis: Low or high correlation\n",
      "HEIGHT3 removed at 3: Correlation Analysis: Low or high correlation\n",
      "BLIND removed at 3: Correlation Analysis: Low or high correlation\n",
      "DECIDE removed at 3: Correlation Analysis: Low or high correlation\n",
      "USENOW3 removed at 3: Correlation Analysis: Low or high correlation\n",
      "FRUITJU1 removed at 3: Correlation Analysis: Low or high correlation\n",
      "FRUIT1 removed at 3: Correlation Analysis: Low or high correlation\n",
      "FVBEANS removed at 3: Correlation Analysis: Low or high correlation\n",
      "FVGREEN removed at 3: Correlation Analysis: Low or high correlation\n",
      "FVORANG removed at 3: Correlation Analysis: Low or high correlation\n",
      "VEGETAB1 removed at 3: Correlation Analysis: Low or high correlation\n",
      "EXERANY2 removed at 3: Correlation Analysis: Low or high correlation\n",
      "SEATBELT removed at 3: Correlation Analysis: Low or high correlation\n",
      "HIVTST6 removed at 3: Correlation Analysis: Low or high correlation\n",
      "QSTLANG removed at 3: Correlation Analysis: Low or high correlation\n",
      "_STSTR removed at 3: Correlation Analysis: Low or high correlation\n",
      "_STRWT removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RAWRAKE removed at 3: Correlation Analysis: Low or high correlation\n",
      "_WT2RAKE removed at 3: Correlation Analysis: Low or high correlation\n",
      "_DUALUSE removed at 3: Correlation Analysis: Low or high correlation\n",
      "_LLCPWT removed at 3: Correlation Analysis: Low or high correlation\n",
      "_LTASTH1 removed at 3: Correlation Analysis: Low or high correlation\n",
      "_CASTHM1 removed at 3: Correlation Analysis: Low or high correlation\n",
      "_ASTHMS1 removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PRACE1 removed at 3: Correlation Analysis: Low or high correlation\n",
      "_MRACE1 removed at 3: Correlation Analysis: Low or high correlation\n",
      "_HISPANC removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RACE removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RACEG21 removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RACEGR3 removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RACE_G1 removed at 3: Correlation Analysis: Low or high correlation\n",
      "HTIN4 removed at 3: Correlation Analysis: Low or high correlation\n",
      "HTM4 removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RFBMI5 removed at 3: Correlation Analysis: Low or high correlation\n",
      "_SMOKER3 removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RFSMOK3 removed at 3: Correlation Analysis: Low or high correlation\n",
      "DRNKANY5 removed at 3: Correlation Analysis: Low or high correlation\n",
      "DROCDY3_ removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RFBING5 removed at 3: Correlation Analysis: Low or high correlation\n",
      "_DRNKWEK removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RFDRHV5 removed at 3: Correlation Analysis: Low or high correlation\n",
      "FTJUDA1_ removed at 3: Correlation Analysis: Low or high correlation\n",
      "FRUTDA1_ removed at 3: Correlation Analysis: Low or high correlation\n",
      "BEANDAY_ removed at 3: Correlation Analysis: Low or high correlation\n",
      "GRENDAY_ removed at 3: Correlation Analysis: Low or high correlation\n",
      "ORNGDAY_ removed at 3: Correlation Analysis: Low or high correlation\n",
      "VEGEDA1_ removed at 3: Correlation Analysis: Low or high correlation\n",
      "_MISFRTN removed at 3: Correlation Analysis: Low or high correlation\n",
      "_MISVEGN removed at 3: Correlation Analysis: Low or high correlation\n",
      "_FRTRESP removed at 3: Correlation Analysis: Low or high correlation\n",
      "_VEGRESP removed at 3: Correlation Analysis: Low or high correlation\n",
      "_FRUTSUM removed at 3: Correlation Analysis: Low or high correlation\n",
      "_VEGESUM removed at 3: Correlation Analysis: Low or high correlation\n",
      "_FRTLT1 removed at 3: Correlation Analysis: Low or high correlation\n",
      "_VEGLT1 removed at 3: Correlation Analysis: Low or high correlation\n",
      "_FRUITEX removed at 3: Correlation Analysis: Low or high correlation\n",
      "_VEGETEX removed at 3: Correlation Analysis: Low or high correlation\n",
      "_TOTINDA removed at 3: Correlation Analysis: Low or high correlation\n",
      "MAXVO2_ removed at 3: Correlation Analysis: Low or high correlation\n",
      "FC60_ removed at 3: Correlation Analysis: Low or high correlation\n",
      "STRFREQ_ removed at 3: Correlation Analysis: Low or high correlation\n",
      "PAMISS1_ removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PACAT1 removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PAINDX1 removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PA150R2 removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PA300R2 removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PA30021 removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PASTRNG removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PAREC1 removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PASTAE1 removed at 3: Correlation Analysis: Low or high correlation\n",
      "_LMTWRK1 removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RFSEAT2 removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RFSEAT3 removed at 3: Correlation Analysis: Low or high correlation\n",
      "_AIDTST3 removed at 3: Correlation Analysis: Low or high correlation\n",
      "Preprocessing complete. Cleaned dataset saved as 'cleaned_dataset.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Print the final removal log for interpretability\n",
    "print(\"\\nRemoval Log:\")\n",
    "for entry in removal_log:\n",
    "    print(entry)\n",
    "\n",
    "print(\"Preprocessing complete. Cleaned dataset saved as 'cleaned_dataset.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SEQNO', '_PSU', 'GENHLTH', 'PHYSHLTH', 'CHECKUP1', 'BPHIGH4', 'BLOODCHO', 'CHOLCHK', 'TOLDHI2', 'CVDSTRK3', 'CHCSCNCR', 'CHCOCNCR', 'CHCCOPD1', 'HAVARTH3', 'CHCKIDNY', 'DIABETE3', 'SEX', 'EDUCA', 'VETERAN3', 'EMPLOY1', 'CHILDREN', 'INTERNET', 'QLACTLM2', 'USEEQUIP', 'DIFFWALK', 'DIFFDRES', 'DIFFALON', 'SMOKE100', 'ALCDAY5', 'STRENGTH', 'FLUSHOT6', 'PNEUVAC3', 'QSTVER', '_RFHLTH', '_HCVU651', '_RFHYPE5', '_CHOLCHK', '_RFCHOL', '_DRDXAR1', '_AGEG5YR', '_AGE65YR', '_AGE80', '_AGE_G', 'WTKG3', '_BMI5', '_BMI5CAT', '_CHLDCNT', '_EDUCAG', '_INCOMG', '_LMTACT1', '_LMTSCL1']\n"
     ]
    }
   ],
   "source": [
    "print(x_train_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CTELENUM', 'PVTRESD1', 'COLGHOUS', 'STATERES', 'CELLFON3', 'LADULT', 'NUMADULT', 'NUMMEN', 'NUMWOMEN', 'CTELNUM1', 'CELLFON2', 'CADULT', 'PVTRESD2', 'CCLGHOUS', 'CSTATE', 'LANDLINE', 'HHADULT', 'POORHLTH', 'BPMEDS', 'ASTHNOW', 'DIABAGE2', 'NUMHHOL2', 'NUMPHON2', 'CPDEMO1', 'PREGNANT', 'SMOKDAY2', 'STOPSMK2', 'LASTSMK2', 'AVEDRNK2', 'DRNK3GE5', 'MAXDRNKS', 'EXRACT11', 'EXEROFT1', 'EXERHMM1', 'EXRACT21', 'EXEROFT2', 'EXERHMM2', 'LMTJOIN3', 'ARTHDIS2', 'ARTHSOCL', 'JOINPAIN', 'FLSHTMY2', 'IMFVPLAC', 'HIVTSTD3', 'WHRTST10', 'PDIABTST', 'PREDIAB1', 'INSULIN', 'BLDSUGAR', 'FEETCHK2', 'DOCTDIAB', 'CHKHEMO3', 'FEETCHK', 'EYEEXAM', 'DIABEYE', 'DIABEDU', 'CAREGIV1', 'CRGVREL1', 'CRGVLNG1', 'CRGVHRS1', 'CRGVPRB1', 'CRGVPERS', 'CRGVHOUS', 'CRGVMST2', 'CRGVEXPT', 'VIDFCLT2', 'VIREDIF3', 'VIPRFVS2', 'VINOCRE2', 'VIEYEXM2', 'VIINSUR2', 'VICTRCT4', 'VIGLUMA2', 'VIMACDG2', 'CIMEMLOS', 'CDHOUSE', 'CDASSIST', 'CDHELP', 'CDSOCIAL', 'CDDISCUS', 'WTCHSALT', 'LONGWTCH', 'DRADVISE', 'ASTHMAGE', 'ASATTACK', 'ASERVIST', 'ASDRVIST', 'ASRCHKUP', 'ASACTLIM', 'ASYMPTOM', 'ASNOSLEP', 'ASTHMED3', 'ASINHALR', 'HAREHAB1', 'STREHAB1', 'CVDASPRN', 'ASPUNSAF', 'RLIVPAIN', 'RDUCHART', 'RDUCSTRK', 'ARTTODAY', 'ARTHWGT', 'ARTHEXER', 'ARTHEDU', 'TETANUS', 'HPVADVC2', 'HPVADSHT', 'SHINGLE2', 'HADMAM', 'HOWLONG', 'HADPAP2', 'LASTPAP2', 'HPVTEST', 'HPLSTTST', 'HADHYST2', 'PROFEXAM', 'LENGEXAM', 'BLDSTOOL', 'LSTBLDS3', 'HADSIGM3', 'HADSGCO1', 'LASTSIG3', 'PCPSAAD2', 'PCPSADI1', 'PCPSARE1', 'PSATEST1', 'PSATIME', 'PCPSARS1', 'PCPSADE1', 'PCDMDECN', 'SCNTMNY1', 'SCNTMEL1', 'SCNTPAID', 'SCNTWRK1', 'SCNTLPAD', 'SCNTLWK1', 'SXORIENT', 'TRNSGNDR', 'RCSGENDR', 'RCSRLTN2', 'CASTHDX2', 'CASTHNO2', 'EMTSUPRT', 'LSATISFY', 'ADPLEASR', 'ADDOWN', 'ADSLEEP', 'ADENERGY', 'ADEAT1', 'ADFAIL', 'ADTHINK', 'ADMOVE', 'MISTMNT', 'ADANXEV', 'MSCODE', '_CHISPNC', '_CRACE1', '_CPRACE', '_CLLCPWT', '_DUALCOR', 'METVL11_', 'METVL21_', 'ACTIN11_', 'ACTIN21_', 'PADUR1_', 'PADUR2_', 'PAFREQ1_', 'PAFREQ2_', '_MINAC11', '_MINAC21', 'PAMIN11_', 'PAMIN21_', 'PA1MIN_', 'PAVIG11_', 'PAVIG21_', 'PA1VIGM_', '_FLSHOT6', '_PNEUMO2', '_FRT16', '_VEG23', '_STATE', 'FMONTH', 'IDATE', 'IMONTH', 'IDAY', 'IYEAR', 'DISPCODE', 'MENTHLTH', 'HLTHPLN1', 'PERSDOC2', 'MEDCOST', 'ASTHMA3', 'ADDEPEV2', 'MARITAL', 'RENTHOM1', 'INCOME2', 'WEIGHT2', 'HEIGHT3', 'BLIND', 'DECIDE', 'USENOW3', 'FRUITJU1', 'FRUIT1', 'FVBEANS', 'FVGREEN', 'FVORANG', 'VEGETAB1', 'EXERANY2', 'SEATBELT', 'HIVTST6', 'QSTLANG', '_STSTR', '_STRWT', '_RAWRAKE', '_WT2RAKE', '_DUALUSE', '_LLCPWT', '_LTASTH1', '_CASTHM1', '_ASTHMS1', '_PRACE1', '_MRACE1', '_HISPANC', '_RACE', '_RACEG21', '_RACEGR3', '_RACE_G1', 'HTIN4', 'HTM4', '_RFBMI5', '_SMOKER3', '_RFSMOK3', 'DRNKANY5', 'DROCDY3_', '_RFBING5', '_DRNKWEK', '_RFDRHV5', 'FTJUDA1_', 'FRUTDA1_', 'BEANDAY_', 'GRENDAY_', 'ORNGDAY_', 'VEGEDA1_', '_MISFRTN', '_MISVEGN', '_FRTRESP', '_VEGRESP', '_FRUTSUM', '_VEGESUM', '_FRTLT1', '_VEGLT1', '_FRUITEX', '_VEGETEX', '_TOTINDA', 'MAXVO2_', 'FC60_', 'STRFREQ_', 'PAMISS1_', '_PACAT1', '_PAINDX1', '_PA150R2', '_PA300R2', '_PA30021', '_PASTRNG', '_PAREC1', '_PASTAE1', '_LMTWRK1', '_RFSEAT2', '_RFSEAT3', '_AIDTST3']\n"
     ]
    }
   ],
   "source": [
    "removed_features = removed_missing_values + removed_variance + removed_correlation\n",
    "print(removed_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\utilisateur\\AppData\\Local\\Temp\\ipykernel_17564\\3861114181.py:15: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  df_conserved.to_excel(output_file_path, index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file generated and saved as conserved_features_output.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your Excel file with all features and their meanings\n",
    "input_file_path = 'BRFSS_2015_Cleaned_Parameters_excel.xlsx'\n",
    "df_parameters = pd.read_excel(input_file_path)\n",
    "\n",
    "# List of conserved features to filter\n",
    "conserved_features = x_train_headers\n",
    "\n",
    "# Filter the DataFrame for conserved features\n",
    "df_conserved = df_parameters[df_parameters['Parameter'].isin(conserved_features)]\n",
    "\n",
    "# Save the filtered data to a new Excel file\n",
    "output_file_path = 'conserved_features_output.xlsx'\n",
    "df_conserved.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"Excel file generated and saved as {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file generated and saved as removed_features_with_description_log.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\utilisateur\\AppData\\Local\\Temp\\ipykernel_17564\\2870947207.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_removed_info['Reason of Removal'] = df_removed_info['Parameter'].map(dict(zip(removed_features_, removal_reasons)))\n",
      "C:\\Users\\utilisateur\\AppData\\Local\\Temp\\ipykernel_17564\\2870947207.py:18: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  df_removed_info.to_excel(output_file_path, index=False)\n"
     ]
    }
   ],
   "source": [
    "# Parse the removal log into a structured format\n",
    "removed_features_ = []\n",
    "removal_reasons = []\n",
    "\n",
    "for log in removal_log:\n",
    "    feature, reason = log.split(\" removed at \")[0], log.split(\": \", 1)[1]\n",
    "    removed_features_.append(feature)\n",
    "    removal_reasons.append(reason)\n",
    "\n",
    "# Filter the DataFrame to include only the removed features\n",
    "df_removed_info = df_parameters[df_parameters['Parameter'].isin(removed_features_)]\n",
    "\n",
    "# Add the reason for removal to the DataFrame\n",
    "df_removed_info['Reason of Removal'] = df_removed_info['Parameter'].map(dict(zip(removed_features_, removal_reasons)))\n",
    "\n",
    "# Save the updated DataFrame with feature names, descriptions, value meanings, and reasons for removal to an Excel file\n",
    "output_file_path = 'removed_features_with_description_log.xlsx'\n",
    "df_removed_info.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"Excel file generated and saved as {output_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
