{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('c:\\\\Users\\\\utilisateur\\\\Documents\\\\GitHub\\\\ML_Project1\\\\ML_project1')\n",
    "         \n",
    "import sys\n",
    "sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport pandas as pd\\n\\n# Load your large dataset\\nfile_path = 'dataset\\\\x_train.csv'\\ndf = pd.read_csv(file_path)\\n\\n# Define the number of rows you want in each smaller file\\nrows_per_file = 50000  # You can change this based on the file size\\n\\n# Split the dataset\\nfor i in range(0, len(df), rows_per_file):\\n    # Create a smaller dataset slice\\n    df_subset = df[i:i+rows_per_file]\\n    \\n    # Save this slice to a new CSV file\\n    output_file = f'small_dataset_part_{i//rows_per_file + 1}.csv'\\n    df_subset.to_csv(output_file, index=False)\\n    print(f'Created {output_file}')\\n\""
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "# Load your large dataset\n",
    "file_path = 'dataset\\\\x_train.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define the number of rows you want in each smaller file\n",
    "rows_per_file = 50000  # You can change this based on the file size\n",
    "\n",
    "# Split the dataset\n",
    "for i in range(0, len(df), rows_per_file):\n",
    "    # Create a smaller dataset slice\n",
    "    df_subset = df[i:i+rows_per_file]\n",
    "    \n",
    "    # Save this slice to a new CSV file\n",
    "    output_file = f'small_dataset_part_{i//rows_per_file + 1}.csv'\n",
    "    df_subset.to_csv(output_file, index=False)\n",
    "    print(f'Created {output_file}')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "file_path = 'dataset\\\\'\n",
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data(file_path)\n",
    "\n",
    "removal_log = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_missing_values = []\n",
    "removed_variance = []\n",
    "removed_correlation = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_and_print_removals(headers, removed_indices, step_name, reason):\n",
    "    \"\"\"\n",
    "    Logs and prints the features removed at each step.\n",
    "\n",
    "    Args:\n",
    "        headers (list): The list of feature names.\n",
    "        removed_indices (list): Indices of features that were removed at the current step.\n",
    "        step_name (str): The name of the step where the features were removed.\n",
    "        reason (str): The reason why the features were removed.\n",
    "    \"\"\"\n",
    "    removed_features = [headers[i] for i in removed_indices]\n",
    "    for feature in removed_features:\n",
    "        removal_log.append(f\"{feature} removed at {step_name}: {reason}\")\n",
    "\n",
    "    print(f\"\\nStep {step_name} - Reason: {reason}:\")\n",
    "    print(f\"Removed {len(removed_features)} features: {removed_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print kept/removed features after each step\n",
    "def print_feature_info(headers, kept_indices, step_name):\n",
    "    \"\"\"\n",
    "    Prints the number of features that were kept and removed after each step, \n",
    "    along with the respective feature names.\n",
    "\n",
    "    Args:\n",
    "        headers (list): The list of feature names.\n",
    "        kept_indices (list): Indices of features that were kept after the step.\n",
    "        step_name (str): The name of the step for which this information is printed.\n",
    "    \"\"\"\n",
    "    kept_features = [headers[i] for i in kept_indices]\n",
    "    removed_features = [headers[i] for i in range(len(headers)) if i not in kept_indices]\n",
    "    \n",
    "    print(f\"\\nStep {step_name}:\")\n",
    "    print(f\"Kept {len(kept_features)} features: {kept_features}\")\n",
    "    print(f\"Removed {len(removed_features)} features: {removed_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_headers(csv_file_path):\n",
    "    \"\"\"\n",
    "    This function extracts the headers (feature names) from the given CSV file.\n",
    "    \n",
    "    Args:\n",
    "        csv_file_path (str): Path to the CSV file from which to extract headers.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of headers (feature names), excluding the 'Id' column.\n",
    "    \"\"\"\n",
    "    with open(csv_file_path, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        headers = next(reader)  # Read the first row as headers\n",
    "    return headers[1:]  # Exclude the first column header as it is 'Id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract headers from x_train.csv\n",
    "x_train_headers = extract_headers(\"dataset\\\\x_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary features: 4\n",
      "Continuous features: 102\n",
      "Categorical features: 215\n",
      "Binary features: ['_FRTRESP', '_VEGRESP', '_FRT16', '_VEG23']\n",
      "Continuous features: ['_STATE', 'FMONTH', 'IDATE', 'IMONTH', 'IDAY', 'SEQNO', '_PSU', 'NUMADULT', 'NUMMEN', 'NUMWOMEN', 'HHADULT', 'PHYSHLTH', 'MENTHLTH', 'POORHLTH', 'DIABAGE2', 'CHILDREN', 'WEIGHT2', 'HEIGHT3', 'ALCDAY5', 'AVEDRNK2', 'DRNK3GE5', 'MAXDRNKS', 'FRUITJU1', 'FRUIT1', 'FVBEANS', 'FVGREEN', 'FVORANG', 'VEGETAB1', 'EXRACT11', 'EXEROFT1', 'EXERHMM1', 'EXRACT21', 'EXEROFT2', 'EXERHMM2', 'STRENGTH', 'JOINPAIN', 'FLSHTMY2', 'IMFVPLAC', 'HIVTSTD3', 'WHRTST10', 'BLDSUGAR', 'FEETCHK2', 'DOCTDIAB', 'CHKHEMO3', 'FEETCHK', 'CRGVREL1', 'CRGVPRB1', 'LONGWTCH', 'ASTHMAGE', 'ASDRVIST', 'ASRCHKUP', 'ASACTLIM', 'SCNTWRK1', 'SCNTLWK1', 'ADPLEASR', 'ADDOWN', 'ADSLEEP', 'ADENERGY', 'ADEAT1', 'ADFAIL', 'ADTHINK', 'ADMOVE', '_STSTR', '_STRWT', '_RAWRAKE', '_WT2RAKE', '_CLLCPWT', '_DUALCOR', '_LLCPWT', '_AGEG5YR', '_AGE80', 'HTIN4', 'HTM4', 'WTKG3', '_BMI5', 'DROCDY3_', '_DRNKWEK', 'FTJUDA1_', 'FRUTDA1_', 'BEANDAY_', 'GRENDAY_', 'ORNGDAY_', 'VEGEDA1_', '_FRUTSUM', '_VEGESUM', 'METVL11_', 'METVL21_', 'MAXVO2_', 'FC60_', 'PADUR1_', 'PADUR2_', 'PAFREQ1_', 'PAFREQ2_', '_MINAC11', '_MINAC21', 'STRFREQ_', 'PAMIN11_', 'PAMIN21_', 'PA1MIN_', 'PAVIG11_', 'PAVIG21_', 'PA1VIGM_']\n",
      "Categorical features: ['IYEAR', 'DISPCODE', 'CTELENUM', 'PVTRESD1', 'COLGHOUS', 'STATERES', 'CELLFON3', 'LADULT', 'CTELNUM1', 'CELLFON2', 'CADULT', 'PVTRESD2', 'CCLGHOUS', 'CSTATE', 'LANDLINE', 'GENHLTH', 'HLTHPLN1', 'PERSDOC2', 'MEDCOST', 'CHECKUP1', 'BPHIGH4', 'BPMEDS', 'BLOODCHO', 'CHOLCHK', 'TOLDHI2', 'CVDSTRK3', 'ASTHMA3', 'ASTHNOW', 'CHCSCNCR', 'CHCOCNCR', 'CHCCOPD1', 'HAVARTH3', 'ADDEPEV2', 'CHCKIDNY', 'DIABETE3', 'SEX', 'MARITAL', 'EDUCA', 'RENTHOM1', 'NUMHHOL2', 'NUMPHON2', 'CPDEMO1', 'VETERAN3', 'EMPLOY1', 'INCOME2', 'INTERNET', 'PREGNANT', 'QLACTLM2', 'USEEQUIP', 'BLIND', 'DECIDE', 'DIFFWALK', 'DIFFDRES', 'DIFFALON', 'SMOKE100', 'SMOKDAY2', 'STOPSMK2', 'LASTSMK2', 'USENOW3', 'EXERANY2', 'LMTJOIN3', 'ARTHDIS2', 'ARTHSOCL', 'SEATBELT', 'FLUSHOT6', 'PNEUVAC3', 'HIVTST6', 'PDIABTST', 'PREDIAB1', 'INSULIN', 'EYEEXAM', 'DIABEYE', 'DIABEDU', 'CAREGIV1', 'CRGVLNG1', 'CRGVHRS1', 'CRGVPERS', 'CRGVHOUS', 'CRGVMST2', 'CRGVEXPT', 'VIDFCLT2', 'VIREDIF3', 'VIPRFVS2', 'VINOCRE2', 'VIEYEXM2', 'VIINSUR2', 'VICTRCT4', 'VIGLUMA2', 'VIMACDG2', 'CIMEMLOS', 'CDHOUSE', 'CDASSIST', 'CDHELP', 'CDSOCIAL', 'CDDISCUS', 'WTCHSALT', 'DRADVISE', 'ASATTACK', 'ASERVIST', 'ASYMPTOM', 'ASNOSLEP', 'ASTHMED3', 'ASINHALR', 'HAREHAB1', 'STREHAB1', 'CVDASPRN', 'ASPUNSAF', 'RLIVPAIN', 'RDUCHART', 'RDUCSTRK', 'ARTTODAY', 'ARTHWGT', 'ARTHEXER', 'ARTHEDU', 'TETANUS', 'HPVADVC2', 'HPVADSHT', 'SHINGLE2', 'HADMAM', 'HOWLONG', 'HADPAP2', 'LASTPAP2', 'HPVTEST', 'HPLSTTST', 'HADHYST2', 'PROFEXAM', 'LENGEXAM', 'BLDSTOOL', 'LSTBLDS3', 'HADSIGM3', 'HADSGCO1', 'LASTSIG3', 'PCPSAAD2', 'PCPSADI1', 'PCPSARE1', 'PSATEST1', 'PSATIME', 'PCPSARS1', 'PCPSADE1', 'PCDMDECN', 'SCNTMNY1', 'SCNTMEL1', 'SCNTPAID', 'SCNTLPAD', 'SXORIENT', 'TRNSGNDR', 'RCSGENDR', 'RCSRLTN2', 'CASTHDX2', 'CASTHNO2', 'EMTSUPRT', 'LSATISFY', 'MISTMNT', 'ADANXEV', 'QSTVER', 'QSTLANG', 'MSCODE', '_CHISPNC', '_CRACE1', '_CPRACE', '_DUALUSE', '_RFHLTH', '_HCVU651', '_RFHYPE5', '_CHOLCHK', '_RFCHOL', '_LTASTH1', '_CASTHM1', '_ASTHMS1', '_DRDXAR1', '_PRACE1', '_MRACE1', '_HISPANC', '_RACE', '_RACEG21', '_RACEGR3', '_RACE_G1', '_AGE65YR', '_AGE_G', '_BMI5CAT', '_RFBMI5', '_CHLDCNT', '_EDUCAG', '_INCOMG', '_SMOKER3', '_RFSMOK3', 'DRNKANY5', '_RFBING5', '_RFDRHV5', '_MISFRTN', '_MISVEGN', '_FRTLT1', '_VEGLT1', '_FRUITEX', '_VEGETEX', '_TOTINDA', 'ACTIN11_', 'ACTIN21_', 'PAMISS1_', '_PACAT1', '_PAINDX1', '_PA150R2', '_PA300R2', '_PA30021', '_PASTRNG', '_PAREC1', '_PASTAE1', '_LMTACT1', '_LMTWRK1', '_LMTSCL1', '_RFSEAT2', '_RFSEAT3', '_FLSHOT6', '_PNEUMO2', '_AIDTST3']\n"
     ]
    }
   ],
   "source": [
    "# Initialize counters and lists\n",
    "binary_count = 0\n",
    "continuous_count = 0\n",
    "categorical_count = 0\n",
    "\n",
    "binary_features = []\n",
    "continuous_features = []\n",
    "categorical_features = []\n",
    "\n",
    "# Threshold for distinguishing categorical from continuous\n",
    "categorical_threshold = 10\n",
    "\n",
    "# Analyze each feature column-wise\n",
    "for col_idx in range(x_train.shape[1]):\n",
    "    column_data = x_train[:, col_idx]\n",
    "    \n",
    "    # Remove missing or empty values to avoid counting them\n",
    "    column_data = column_data[~np.isnan(column_data)]  # Remove NaN values\n",
    "\n",
    "    # Get unique values\n",
    "    unique_values = np.unique(column_data)\n",
    "    unique_count = len(unique_values)\n",
    "\n",
    "    # Binary feature: 2 unique values\n",
    "    if unique_count == 2 and set(unique_values) == {0, 1}:\n",
    "        binary_count += 1\n",
    "        binary_features.append(x_train_headers[col_idx])\n",
    "    \n",
    "    # Continuous feature: more than categorical_threshold unique values\n",
    "    elif unique_count > categorical_threshold:\n",
    "        continuous_count += 1\n",
    "        continuous_features.append(x_train_headers[col_idx])\n",
    "    \n",
    "    # Categorical feature: 3-10 unique values (or another condition you define)\n",
    "    else:\n",
    "        categorical_count += 1\n",
    "        categorical_features.append(x_train_headers[col_idx])\n",
    "\n",
    "# Output the counts and the feature types\n",
    "print(f\"Binary features: {binary_count}\")\n",
    "print(f\"Continuous features: {continuous_count}\")\n",
    "print(f\"Categorical features: {categorical_count}\")\n",
    "\n",
    "# Optionally, display the lists of features by type\n",
    "print(\"Binary features:\", binary_features)\n",
    "print(\"Continuous features:\", continuous_features)\n",
    "print(\"Categorical features:\", categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Remove features with too many missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_missing_values(headers, data, threshold=0.25):\n",
    "    \"\"\"\n",
    "    Removes features (columns) from the dataset that have more than the specified\n",
    "    percentage of missing values.\n",
    "\n",
    "    Args:\n",
    "        headers (list): The list of feature names.\n",
    "        data (np.array): The dataset (numpy array) with features as columns.\n",
    "        threshold (float): The maximum allowed percentage of missing values (default is 25%).\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - valid_columns (list): The indices of the features that were kept.\n",
    "            - filtered_data (np.array): The filtered dataset with only the valid columns.\n",
    "    \"\"\"\n",
    "    # Find the percentage of missing values for each column\n",
    "    missing_values = np.isnan(data).mean(axis=0)\n",
    "    valid_columns = np.where(missing_values <= threshold)[0]\n",
    "    removed_columns = np.where(missing_values > threshold)[0]\n",
    "\n",
    "    # Store the removed features\n",
    "    removed_features_names = [headers[i] for i in removed_columns]\n",
    "    removed_missing_values.extend(removed_features_names)\n",
    "    \n",
    "    # Log removed features\n",
    "    log_and_print_removals(headers, removed_columns, \"1: Remove Missing Values\", \"Too many missing values\")\n",
    "    \n",
    "    # Filter out the columns with too many missing values\n",
    "    filtered_data = data[:, valid_columns]\n",
    "    return valid_columns, filtered_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 1: Remove Missing Values - Reason: Too many missing values:\n",
      "Removed 178 features: ['CTELENUM', 'PVTRESD1', 'COLGHOUS', 'STATERES', 'CELLFON3', 'LADULT', 'NUMADULT', 'NUMMEN', 'NUMWOMEN', 'CTELNUM1', 'CELLFON2', 'CADULT', 'PVTRESD2', 'CCLGHOUS', 'CSTATE', 'LANDLINE', 'HHADULT', 'POORHLTH', 'BPMEDS', 'ASTHNOW', 'DIABAGE2', 'NUMHHOL2', 'NUMPHON2', 'CPDEMO1', 'PREGNANT', 'SMOKDAY2', 'STOPSMK2', 'LASTSMK2', 'AVEDRNK2', 'DRNK3GE5', 'MAXDRNKS', 'EXRACT11', 'EXEROFT1', 'EXERHMM1', 'EXRACT21', 'EXEROFT2', 'EXERHMM2', 'LMTJOIN3', 'ARTHDIS2', 'ARTHSOCL', 'JOINPAIN', 'FLSHTMY2', 'IMFVPLAC', 'HIVTSTD3', 'WHRTST10', 'PDIABTST', 'PREDIAB1', 'INSULIN', 'BLDSUGAR', 'FEETCHK2', 'DOCTDIAB', 'CHKHEMO3', 'FEETCHK', 'EYEEXAM', 'DIABEYE', 'DIABEDU', 'CAREGIV1', 'CRGVREL1', 'CRGVLNG1', 'CRGVHRS1', 'CRGVPRB1', 'CRGVPERS', 'CRGVHOUS', 'CRGVMST2', 'CRGVEXPT', 'VIDFCLT2', 'VIREDIF3', 'VIPRFVS2', 'VINOCRE2', 'VIEYEXM2', 'VIINSUR2', 'VICTRCT4', 'VIGLUMA2', 'VIMACDG2', 'CIMEMLOS', 'CDHOUSE', 'CDASSIST', 'CDHELP', 'CDSOCIAL', 'CDDISCUS', 'WTCHSALT', 'LONGWTCH', 'DRADVISE', 'ASTHMAGE', 'ASATTACK', 'ASERVIST', 'ASDRVIST', 'ASRCHKUP', 'ASACTLIM', 'ASYMPTOM', 'ASNOSLEP', 'ASTHMED3', 'ASINHALR', 'HAREHAB1', 'STREHAB1', 'CVDASPRN', 'ASPUNSAF', 'RLIVPAIN', 'RDUCHART', 'RDUCSTRK', 'ARTTODAY', 'ARTHWGT', 'ARTHEXER', 'ARTHEDU', 'TETANUS', 'HPVADVC2', 'HPVADSHT', 'SHINGLE2', 'HADMAM', 'HOWLONG', 'HADPAP2', 'LASTPAP2', 'HPVTEST', 'HPLSTTST', 'HADHYST2', 'PROFEXAM', 'LENGEXAM', 'BLDSTOOL', 'LSTBLDS3', 'HADSIGM3', 'HADSGCO1', 'LASTSIG3', 'PCPSAAD2', 'PCPSADI1', 'PCPSARE1', 'PSATEST1', 'PSATIME', 'PCPSARS1', 'PCPSADE1', 'PCDMDECN', 'SCNTMNY1', 'SCNTMEL1', 'SCNTPAID', 'SCNTWRK1', 'SCNTLPAD', 'SCNTLWK1', 'SXORIENT', 'TRNSGNDR', 'RCSGENDR', 'RCSRLTN2', 'CASTHDX2', 'CASTHNO2', 'EMTSUPRT', 'LSATISFY', 'ADPLEASR', 'ADDOWN', 'ADSLEEP', 'ADENERGY', 'ADEAT1', 'ADFAIL', 'ADTHINK', 'ADMOVE', 'MISTMNT', 'ADANXEV', 'MSCODE', '_CHISPNC', '_CRACE1', '_CPRACE', '_CLLCPWT', '_DUALCOR', 'METVL11_', 'METVL21_', 'ACTIN11_', 'ACTIN21_', 'PADUR1_', 'PADUR2_', 'PAFREQ1_', 'PAFREQ2_', '_MINAC11', '_MINAC21', 'PAMIN11_', 'PAMIN21_', 'PA1MIN_', 'PAVIG11_', 'PAVIG21_', 'PA1VIGM_', '_FLSHOT6', '_PNEUMO2']\n",
      "Filtered dataset shape: (328135, 143)\n",
      "Remaining features: ['_STATE', 'FMONTH', 'IDATE', 'IMONTH', 'IDAY', 'IYEAR', 'DISPCODE', 'SEQNO', '_PSU', 'GENHLTH', 'PHYSHLTH', 'MENTHLTH', 'HLTHPLN1', 'PERSDOC2', 'MEDCOST', 'CHECKUP1', 'BPHIGH4', 'BLOODCHO', 'CHOLCHK', 'TOLDHI2', 'CVDSTRK3', 'ASTHMA3', 'CHCSCNCR', 'CHCOCNCR', 'CHCCOPD1', 'HAVARTH3', 'ADDEPEV2', 'CHCKIDNY', 'DIABETE3', 'SEX', 'MARITAL', 'EDUCA', 'RENTHOM1', 'VETERAN3', 'EMPLOY1', 'CHILDREN', 'INCOME2', 'INTERNET', 'WEIGHT2', 'HEIGHT3', 'QLACTLM2', 'USEEQUIP', 'BLIND', 'DECIDE', 'DIFFWALK', 'DIFFDRES', 'DIFFALON', 'SMOKE100', 'USENOW3', 'ALCDAY5', 'FRUITJU1', 'FRUIT1', 'FVBEANS', 'FVGREEN', 'FVORANG', 'VEGETAB1', 'EXERANY2', 'STRENGTH', 'SEATBELT', 'FLUSHOT6', 'PNEUVAC3', 'HIVTST6', 'QSTVER', 'QSTLANG', '_STSTR', '_STRWT', '_RAWRAKE', '_WT2RAKE', '_DUALUSE', '_LLCPWT', '_RFHLTH', '_HCVU651', '_RFHYPE5', '_CHOLCHK', '_RFCHOL', '_LTASTH1', '_CASTHM1', '_ASTHMS1', '_DRDXAR1', '_PRACE1', '_MRACE1', '_HISPANC', '_RACE', '_RACEG21', '_RACEGR3', '_RACE_G1', '_AGEG5YR', '_AGE65YR', '_AGE80', '_AGE_G', 'HTIN4', 'HTM4', 'WTKG3', '_BMI5', '_BMI5CAT', '_RFBMI5', '_CHLDCNT', '_EDUCAG', '_INCOMG', '_SMOKER3', '_RFSMOK3', 'DRNKANY5', 'DROCDY3_', '_RFBING5', '_DRNKWEK', '_RFDRHV5', 'FTJUDA1_', 'FRUTDA1_', 'BEANDAY_', 'GRENDAY_', 'ORNGDAY_', 'VEGEDA1_', '_MISFRTN', '_MISVEGN', '_FRTRESP', '_VEGRESP', '_FRUTSUM', '_VEGESUM', '_FRTLT1', '_VEGLT1', '_FRT16', '_VEG23', '_FRUITEX', '_VEGETEX', '_TOTINDA', 'MAXVO2_', 'FC60_', 'STRFREQ_', 'PAMISS1_', '_PACAT1', '_PAINDX1', '_PA150R2', '_PA300R2', '_PA30021', '_PASTRNG', '_PAREC1', '_PASTAE1', '_LMTACT1', '_LMTWRK1', '_LMTSCL1', '_RFSEAT2', '_RFSEAT3', '_AIDTST3']\n",
      "Removed features due to missing values: ['CTELENUM', 'PVTRESD1', 'COLGHOUS', 'STATERES', 'CELLFON3', 'LADULT', 'NUMADULT', 'NUMMEN', 'NUMWOMEN', 'CTELNUM1', 'CELLFON2', 'CADULT', 'PVTRESD2', 'CCLGHOUS', 'CSTATE', 'LANDLINE', 'HHADULT', 'POORHLTH', 'BPMEDS', 'ASTHNOW', 'DIABAGE2', 'NUMHHOL2', 'NUMPHON2', 'CPDEMO1', 'PREGNANT', 'SMOKDAY2', 'STOPSMK2', 'LASTSMK2', 'AVEDRNK2', 'DRNK3GE5', 'MAXDRNKS', 'EXRACT11', 'EXEROFT1', 'EXERHMM1', 'EXRACT21', 'EXEROFT2', 'EXERHMM2', 'LMTJOIN3', 'ARTHDIS2', 'ARTHSOCL', 'JOINPAIN', 'FLSHTMY2', 'IMFVPLAC', 'HIVTSTD3', 'WHRTST10', 'PDIABTST', 'PREDIAB1', 'INSULIN', 'BLDSUGAR', 'FEETCHK2', 'DOCTDIAB', 'CHKHEMO3', 'FEETCHK', 'EYEEXAM', 'DIABEYE', 'DIABEDU', 'CAREGIV1', 'CRGVREL1', 'CRGVLNG1', 'CRGVHRS1', 'CRGVPRB1', 'CRGVPERS', 'CRGVHOUS', 'CRGVMST2', 'CRGVEXPT', 'VIDFCLT2', 'VIREDIF3', 'VIPRFVS2', 'VINOCRE2', 'VIEYEXM2', 'VIINSUR2', 'VICTRCT4', 'VIGLUMA2', 'VIMACDG2', 'CIMEMLOS', 'CDHOUSE', 'CDASSIST', 'CDHELP', 'CDSOCIAL', 'CDDISCUS', 'WTCHSALT', 'LONGWTCH', 'DRADVISE', 'ASTHMAGE', 'ASATTACK', 'ASERVIST', 'ASDRVIST', 'ASRCHKUP', 'ASACTLIM', 'ASYMPTOM', 'ASNOSLEP', 'ASTHMED3', 'ASINHALR', 'HAREHAB1', 'STREHAB1', 'CVDASPRN', 'ASPUNSAF', 'RLIVPAIN', 'RDUCHART', 'RDUCSTRK', 'ARTTODAY', 'ARTHWGT', 'ARTHEXER', 'ARTHEDU', 'TETANUS', 'HPVADVC2', 'HPVADSHT', 'SHINGLE2', 'HADMAM', 'HOWLONG', 'HADPAP2', 'LASTPAP2', 'HPVTEST', 'HPLSTTST', 'HADHYST2', 'PROFEXAM', 'LENGEXAM', 'BLDSTOOL', 'LSTBLDS3', 'HADSIGM3', 'HADSGCO1', 'LASTSIG3', 'PCPSAAD2', 'PCPSADI1', 'PCPSARE1', 'PSATEST1', 'PSATIME', 'PCPSARS1', 'PCPSADE1', 'PCDMDECN', 'SCNTMNY1', 'SCNTMEL1', 'SCNTPAID', 'SCNTWRK1', 'SCNTLPAD', 'SCNTLWK1', 'SXORIENT', 'TRNSGNDR', 'RCSGENDR', 'RCSRLTN2', 'CASTHDX2', 'CASTHNO2', 'EMTSUPRT', 'LSATISFY', 'ADPLEASR', 'ADDOWN', 'ADSLEEP', 'ADENERGY', 'ADEAT1', 'ADFAIL', 'ADTHINK', 'ADMOVE', 'MISTMNT', 'ADANXEV', 'MSCODE', '_CHISPNC', '_CRACE1', '_CPRACE', '_CLLCPWT', '_DUALCOR', 'METVL11_', 'METVL21_', 'ACTIN11_', 'ACTIN21_', 'PADUR1_', 'PADUR2_', 'PAFREQ1_', 'PAFREQ2_', '_MINAC11', '_MINAC21', 'PAMIN11_', 'PAMIN21_', 'PA1MIN_', 'PAVIG11_', 'PAVIG21_', 'PA1VIGM_', '_FLSHOT6', '_PNEUMO2']\n"
     ]
    }
   ],
   "source": [
    "removed_missing_values = []  # Initialize the list to store removed features\n",
    "\n",
    "# Apply the function to remove columns with too many missing values\n",
    "valid_columns, x_train_filtered = remove_missing_values(x_train_headers, x_train)\n",
    "\n",
    "# Update headers to match the filtered dataset\n",
    "x_train_headers_filtered = [x_train_headers[i] for i in valid_columns]\n",
    "\n",
    "# Display results\n",
    "print(\"Filtered dataset shape:\", x_train_filtered.shape)\n",
    "print(\"Remaining features:\", x_train_headers_filtered)\n",
    "print(\"Removed features due to missing values:\", removed_missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: All remaining columns meet the missing value threshold.\n"
     ]
    }
   ],
   "source": [
    "#Check that No Columns Exceed the Missing Value Threshold\n",
    "remaining_missing_percentage = np.isnan(x_train_filtered).mean(axis=0)\n",
    "if np.all(remaining_missing_percentage <= 0.25):\n",
    "    print(\"Success: All remaining columns meet the missing value threshold.\")\n",
    "else:\n",
    "    print(\"Warning: Some columns still exceed the missing value threshold.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Transform categorical data into binary data by hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded dataset shape: (328135, 463)\n",
      "Encoded headers: ['_STATE', 'FMONTH', 'IDATE', 'IMONTH', 'IDAY', 'IYEAR_2015.0_encoded', 'IYEAR_2016.0_encoded', 'DISPCODE_1100.0_encoded', 'DISPCODE_1200.0_encoded', 'SEQNO', '_PSU', 'GENHLTH_1.0_encoded', 'GENHLTH_2.0_encoded', 'GENHLTH_3.0_encoded', 'GENHLTH_4.0_encoded', 'GENHLTH_5.0_encoded', 'GENHLTH_7.0_encoded', 'GENHLTH_9.0_encoded', 'PHYSHLTH', 'MENTHLTH', 'HLTHPLN1_1.0_encoded', 'HLTHPLN1_2.0_encoded', 'HLTHPLN1_7.0_encoded', 'HLTHPLN1_9.0_encoded', 'PERSDOC2_1.0_encoded', 'PERSDOC2_2.0_encoded', 'PERSDOC2_3.0_encoded', 'PERSDOC2_7.0_encoded', 'PERSDOC2_9.0_encoded', 'MEDCOST_1.0_encoded', 'MEDCOST_2.0_encoded', 'MEDCOST_7.0_encoded', 'MEDCOST_9.0_encoded', 'CHECKUP1_1.0_encoded', 'CHECKUP1_2.0_encoded', 'CHECKUP1_3.0_encoded', 'CHECKUP1_4.0_encoded', 'CHECKUP1_7.0_encoded', 'CHECKUP1_8.0_encoded', 'CHECKUP1_9.0_encoded', 'BPHIGH4_1.0_encoded', 'BPHIGH4_2.0_encoded', 'BPHIGH4_3.0_encoded', 'BPHIGH4_4.0_encoded', 'BPHIGH4_7.0_encoded', 'BPHIGH4_9.0_encoded', 'BLOODCHO_1.0_encoded', 'BLOODCHO_2.0_encoded', 'BLOODCHO_7.0_encoded', 'BLOODCHO_9.0_encoded', 'CHOLCHK_1.0_encoded', 'CHOLCHK_2.0_encoded', 'CHOLCHK_3.0_encoded', 'CHOLCHK_4.0_encoded', 'CHOLCHK_7.0_encoded', 'CHOLCHK_9.0_encoded', 'TOLDHI2_1.0_encoded', 'TOLDHI2_2.0_encoded', 'TOLDHI2_7.0_encoded', 'TOLDHI2_9.0_encoded', 'CVDSTRK3_1.0_encoded', 'CVDSTRK3_2.0_encoded', 'CVDSTRK3_7.0_encoded', 'CVDSTRK3_9.0_encoded', 'ASTHMA3_1.0_encoded', 'ASTHMA3_2.0_encoded', 'ASTHMA3_7.0_encoded', 'ASTHMA3_9.0_encoded', 'CHCSCNCR_1.0_encoded', 'CHCSCNCR_2.0_encoded', 'CHCSCNCR_7.0_encoded', 'CHCSCNCR_9.0_encoded', 'CHCOCNCR_1.0_encoded', 'CHCOCNCR_2.0_encoded', 'CHCOCNCR_7.0_encoded', 'CHCOCNCR_9.0_encoded', 'CHCCOPD1_1.0_encoded', 'CHCCOPD1_2.0_encoded', 'CHCCOPD1_7.0_encoded', 'CHCCOPD1_9.0_encoded', 'HAVARTH3_1.0_encoded', 'HAVARTH3_2.0_encoded', 'HAVARTH3_7.0_encoded', 'HAVARTH3_9.0_encoded', 'ADDEPEV2_1.0_encoded', 'ADDEPEV2_2.0_encoded', 'ADDEPEV2_7.0_encoded', 'ADDEPEV2_9.0_encoded', 'CHCKIDNY_1.0_encoded', 'CHCKIDNY_2.0_encoded', 'CHCKIDNY_7.0_encoded', 'CHCKIDNY_9.0_encoded', 'DIABETE3_1.0_encoded', 'DIABETE3_2.0_encoded', 'DIABETE3_3.0_encoded', 'DIABETE3_4.0_encoded', 'DIABETE3_7.0_encoded', 'DIABETE3_9.0_encoded', 'SEX_1.0_encoded', 'SEX_2.0_encoded', 'MARITAL_1.0_encoded', 'MARITAL_2.0_encoded', 'MARITAL_3.0_encoded', 'MARITAL_4.0_encoded', 'MARITAL_5.0_encoded', 'MARITAL_6.0_encoded', 'MARITAL_9.0_encoded', 'EDUCA_1.0_encoded', 'EDUCA_2.0_encoded', 'EDUCA_3.0_encoded', 'EDUCA_4.0_encoded', 'EDUCA_5.0_encoded', 'EDUCA_6.0_encoded', 'EDUCA_9.0_encoded', 'RENTHOM1_1.0_encoded', 'RENTHOM1_2.0_encoded', 'RENTHOM1_3.0_encoded', 'RENTHOM1_7.0_encoded', 'RENTHOM1_9.0_encoded', 'VETERAN3_1.0_encoded', 'VETERAN3_2.0_encoded', 'VETERAN3_7.0_encoded', 'VETERAN3_9.0_encoded', 'EMPLOY1_1.0_encoded', 'EMPLOY1_2.0_encoded', 'EMPLOY1_3.0_encoded', 'EMPLOY1_4.0_encoded', 'EMPLOY1_5.0_encoded', 'EMPLOY1_6.0_encoded', 'EMPLOY1_7.0_encoded', 'EMPLOY1_8.0_encoded', 'EMPLOY1_9.0_encoded', 'CHILDREN', 'INCOME2_1.0_encoded', 'INCOME2_2.0_encoded', 'INCOME2_3.0_encoded', 'INCOME2_4.0_encoded', 'INCOME2_5.0_encoded', 'INCOME2_6.0_encoded', 'INCOME2_7.0_encoded', 'INCOME2_8.0_encoded', 'INCOME2_77.0_encoded', 'INCOME2_99.0_encoded', 'INTERNET_1.0_encoded', 'INTERNET_2.0_encoded', 'INTERNET_7.0_encoded', 'INTERNET_9.0_encoded', 'WEIGHT2', 'HEIGHT3', 'QLACTLM2_1.0_encoded', 'QLACTLM2_2.0_encoded', 'QLACTLM2_7.0_encoded', 'QLACTLM2_9.0_encoded', 'USEEQUIP_1.0_encoded', 'USEEQUIP_2.0_encoded', 'USEEQUIP_7.0_encoded', 'USEEQUIP_9.0_encoded', 'BLIND_1.0_encoded', 'BLIND_2.0_encoded', 'BLIND_7.0_encoded', 'BLIND_9.0_encoded', 'DECIDE_1.0_encoded', 'DECIDE_2.0_encoded', 'DECIDE_7.0_encoded', 'DECIDE_9.0_encoded', 'DIFFWALK_1.0_encoded', 'DIFFWALK_2.0_encoded', 'DIFFWALK_7.0_encoded', 'DIFFWALK_9.0_encoded', 'DIFFDRES_1.0_encoded', 'DIFFDRES_2.0_encoded', 'DIFFDRES_7.0_encoded', 'DIFFDRES_9.0_encoded', 'DIFFALON_1.0_encoded', 'DIFFALON_2.0_encoded', 'DIFFALON_7.0_encoded', 'DIFFALON_9.0_encoded', 'SMOKE100_1.0_encoded', 'SMOKE100_2.0_encoded', 'SMOKE100_7.0_encoded', 'SMOKE100_9.0_encoded', 'USENOW3_1.0_encoded', 'USENOW3_2.0_encoded', 'USENOW3_3.0_encoded', 'USENOW3_7.0_encoded', 'USENOW3_9.0_encoded', 'ALCDAY5', 'FRUITJU1', 'FRUIT1', 'FVBEANS', 'FVGREEN', 'FVORANG', 'VEGETAB1', 'EXERANY2_1.0_encoded', 'EXERANY2_2.0_encoded', 'EXERANY2_7.0_encoded', 'EXERANY2_9.0_encoded', 'STRENGTH', 'SEATBELT_1.0_encoded', 'SEATBELT_2.0_encoded', 'SEATBELT_3.0_encoded', 'SEATBELT_4.0_encoded', 'SEATBELT_5.0_encoded', 'SEATBELT_7.0_encoded', 'SEATBELT_8.0_encoded', 'SEATBELT_9.0_encoded', 'FLUSHOT6_1.0_encoded', 'FLUSHOT6_2.0_encoded', 'FLUSHOT6_7.0_encoded', 'FLUSHOT6_9.0_encoded', 'PNEUVAC3_1.0_encoded', 'PNEUVAC3_2.0_encoded', 'PNEUVAC3_7.0_encoded', 'PNEUVAC3_9.0_encoded', 'HIVTST6_1.0_encoded', 'HIVTST6_2.0_encoded', 'HIVTST6_7.0_encoded', 'HIVTST6_9.0_encoded', 'QSTVER_10.0_encoded', 'QSTVER_11.0_encoded', 'QSTVER_12.0_encoded', 'QSTVER_13.0_encoded', 'QSTVER_20.0_encoded', 'QSTVER_21.0_encoded', 'QSTVER_22.0_encoded', 'QSTVER_23.0_encoded', 'QSTLANG_1.0_encoded', 'QSTLANG_2.0_encoded', 'QSTLANG_3.0_encoded', '_STSTR', '_STRWT', '_RAWRAKE', '_WT2RAKE', '_DUALUSE_1.0_encoded', '_DUALUSE_2.0_encoded', '_DUALUSE_9.0_encoded', '_LLCPWT', '_RFHLTH_1.0_encoded', '_RFHLTH_2.0_encoded', '_RFHLTH_9.0_encoded', '_HCVU651_1.0_encoded', '_HCVU651_2.0_encoded', '_HCVU651_9.0_encoded', '_RFHYPE5_1.0_encoded', '_RFHYPE5_2.0_encoded', '_RFHYPE5_9.0_encoded', '_CHOLCHK_1.0_encoded', '_CHOLCHK_2.0_encoded', '_CHOLCHK_3.0_encoded', '_CHOLCHK_9.0_encoded', '_RFCHOL_1.0_encoded', '_RFCHOL_2.0_encoded', '_RFCHOL_9.0_encoded', '_LTASTH1_1.0_encoded', '_LTASTH1_2.0_encoded', '_LTASTH1_9.0_encoded', '_CASTHM1_1.0_encoded', '_CASTHM1_2.0_encoded', '_CASTHM1_9.0_encoded', '_ASTHMS1_1.0_encoded', '_ASTHMS1_2.0_encoded', '_ASTHMS1_3.0_encoded', '_ASTHMS1_9.0_encoded', '_DRDXAR1_1.0_encoded', '_DRDXAR1_2.0_encoded', '_PRACE1_1.0_encoded', '_PRACE1_2.0_encoded', '_PRACE1_3.0_encoded', '_PRACE1_4.0_encoded', '_PRACE1_5.0_encoded', '_PRACE1_6.0_encoded', '_PRACE1_7.0_encoded', '_PRACE1_8.0_encoded', '_PRACE1_77.0_encoded', '_PRACE1_99.0_encoded', '_MRACE1_1.0_encoded', '_MRACE1_2.0_encoded', '_MRACE1_3.0_encoded', '_MRACE1_4.0_encoded', '_MRACE1_5.0_encoded', '_MRACE1_6.0_encoded', '_MRACE1_7.0_encoded', '_MRACE1_77.0_encoded', '_MRACE1_99.0_encoded', '_HISPANC_1.0_encoded', '_HISPANC_2.0_encoded', '_HISPANC_9.0_encoded', '_RACE_1.0_encoded', '_RACE_2.0_encoded', '_RACE_3.0_encoded', '_RACE_4.0_encoded', '_RACE_5.0_encoded', '_RACE_6.0_encoded', '_RACE_7.0_encoded', '_RACE_8.0_encoded', '_RACE_9.0_encoded', '_RACEG21_1.0_encoded', '_RACEG21_2.0_encoded', '_RACEG21_9.0_encoded', '_RACEGR3_1.0_encoded', '_RACEGR3_2.0_encoded', '_RACEGR3_3.0_encoded', '_RACEGR3_4.0_encoded', '_RACEGR3_5.0_encoded', '_RACEGR3_9.0_encoded', '_RACE_G1_1.0_encoded', '_RACE_G1_2.0_encoded', '_RACE_G1_3.0_encoded', '_RACE_G1_4.0_encoded', '_RACE_G1_5.0_encoded', '_AGEG5YR', '_AGE65YR_1.0_encoded', '_AGE65YR_2.0_encoded', '_AGE65YR_3.0_encoded', '_AGE80', '_AGE_G_1.0_encoded', '_AGE_G_2.0_encoded', '_AGE_G_3.0_encoded', '_AGE_G_4.0_encoded', '_AGE_G_5.0_encoded', '_AGE_G_6.0_encoded', 'HTIN4', 'HTM4', 'WTKG3', '_BMI5', '_BMI5CAT_1.0_encoded', '_BMI5CAT_2.0_encoded', '_BMI5CAT_3.0_encoded', '_BMI5CAT_4.0_encoded', '_RFBMI5_1.0_encoded', '_RFBMI5_2.0_encoded', '_RFBMI5_9.0_encoded', '_CHLDCNT_1.0_encoded', '_CHLDCNT_2.0_encoded', '_CHLDCNT_3.0_encoded', '_CHLDCNT_4.0_encoded', '_CHLDCNT_5.0_encoded', '_CHLDCNT_6.0_encoded', '_CHLDCNT_9.0_encoded', '_EDUCAG_1.0_encoded', '_EDUCAG_2.0_encoded', '_EDUCAG_3.0_encoded', '_EDUCAG_4.0_encoded', '_EDUCAG_9.0_encoded', '_INCOMG_1.0_encoded', '_INCOMG_2.0_encoded', '_INCOMG_3.0_encoded', '_INCOMG_4.0_encoded', '_INCOMG_5.0_encoded', '_INCOMG_9.0_encoded', '_SMOKER3_1.0_encoded', '_SMOKER3_2.0_encoded', '_SMOKER3_3.0_encoded', '_SMOKER3_4.0_encoded', '_SMOKER3_9.0_encoded', '_RFSMOK3_1.0_encoded', '_RFSMOK3_2.0_encoded', '_RFSMOK3_9.0_encoded', 'DRNKANY5_1.0_encoded', 'DRNKANY5_2.0_encoded', 'DRNKANY5_7.0_encoded', 'DRNKANY5_9.0_encoded', 'DROCDY3_', '_RFBING5_1.0_encoded', '_RFBING5_2.0_encoded', '_RFBING5_9.0_encoded', '_DRNKWEK', '_RFDRHV5_1.0_encoded', '_RFDRHV5_2.0_encoded', '_RFDRHV5_9.0_encoded', 'FTJUDA1_', 'FRUTDA1_', 'BEANDAY_', 'GRENDAY_', 'ORNGDAY_', 'VEGEDA1_', '_MISFRTN_0.0_encoded', '_MISFRTN_1.0_encoded', '_MISFRTN_2.0_encoded', '_MISVEGN_0.0_encoded', '_MISVEGN_1.0_encoded', '_MISVEGN_2.0_encoded', '_MISVEGN_3.0_encoded', '_MISVEGN_4.0_encoded', '_FRTRESP', '_VEGRESP', '_FRUTSUM', '_VEGESUM', '_FRTLT1_1.0_encoded', '_FRTLT1_2.0_encoded', '_FRTLT1_9.0_encoded', '_VEGLT1_1.0_encoded', '_VEGLT1_2.0_encoded', '_VEGLT1_9.0_encoded', '_FRT16', '_VEG23', '_FRUITEX_0.0_encoded', '_FRUITEX_1.0_encoded', '_FRUITEX_2.0_encoded', '_VEGETEX_0.0_encoded', '_VEGETEX_1.0_encoded', '_VEGETEX_2.0_encoded', '_TOTINDA_1.0_encoded', '_TOTINDA_2.0_encoded', '_TOTINDA_9.0_encoded', 'MAXVO2_', 'FC60_', 'STRFREQ_', 'PAMISS1__0.0_encoded', 'PAMISS1__1.0_encoded', 'PAMISS1__9.0_encoded', '_PACAT1_1.0_encoded', '_PACAT1_2.0_encoded', '_PACAT1_3.0_encoded', '_PACAT1_4.0_encoded', '_PACAT1_9.0_encoded', '_PAINDX1_1.0_encoded', '_PAINDX1_2.0_encoded', '_PAINDX1_9.0_encoded', '_PA150R2_1.0_encoded', '_PA150R2_2.0_encoded', '_PA150R2_3.0_encoded', '_PA150R2_9.0_encoded', '_PA300R2_1.0_encoded', '_PA300R2_2.0_encoded', '_PA300R2_3.0_encoded', '_PA300R2_9.0_encoded', '_PA30021_1.0_encoded', '_PA30021_2.0_encoded', '_PA30021_9.0_encoded', '_PASTRNG_1.0_encoded', '_PASTRNG_2.0_encoded', '_PASTRNG_9.0_encoded', '_PAREC1_1.0_encoded', '_PAREC1_2.0_encoded', '_PAREC1_3.0_encoded', '_PAREC1_4.0_encoded', '_PAREC1_9.0_encoded', '_PASTAE1_1.0_encoded', '_PASTAE1_2.0_encoded', '_PASTAE1_9.0_encoded', '_LMTACT1_1.0_encoded', '_LMTACT1_2.0_encoded', '_LMTACT1_3.0_encoded', '_LMTACT1_9.0_encoded', '_LMTWRK1_1.0_encoded', '_LMTWRK1_2.0_encoded', '_LMTWRK1_3.0_encoded', '_LMTWRK1_9.0_encoded', '_LMTSCL1_1.0_encoded', '_LMTSCL1_2.0_encoded', '_LMTSCL1_3.0_encoded', '_LMTSCL1_4.0_encoded', '_LMTSCL1_9.0_encoded', '_RFSEAT2_1.0_encoded', '_RFSEAT2_2.0_encoded', '_RFSEAT2_9.0_encoded', '_RFSEAT3_1.0_encoded', '_RFSEAT3_2.0_encoded', '_RFSEAT3_9.0_encoded', '_AIDTST3_1.0_encoded', '_AIDTST3_2.0_encoded', '_AIDTST3_9.0_encoded']\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(data, headers, categorical_columns):\n",
    "    \"\"\"\n",
    "    Transforms categorical features into binary (one-hot encoded) features.\n",
    "\n",
    "    Args:\n",
    "        data (np.array): The dataset as a numpy array.\n",
    "        headers (list): List of feature names corresponding to data columns.\n",
    "        categorical_columns (list): List of indices of categorical features in the dataset.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Updated dataset with one-hot encoded features.\n",
    "        list: Updated headers with new binary feature names.\n",
    "    \"\"\"\n",
    "    updated_data = []\n",
    "    updated_headers = []\n",
    "\n",
    "    for col_idx in range(data.shape[1]):\n",
    "        if col_idx in categorical_columns:\n",
    "            # Get unique categories for this feature\n",
    "            unique_categories = np.unique(data[~np.isnan(data[:, col_idx]), col_idx])\n",
    "            \n",
    "            # Create binary columns for each category\n",
    "            for category in unique_categories:\n",
    "                binary_column = (data[:, col_idx] == category).astype(int)\n",
    "                updated_data.append(binary_column)\n",
    "                \n",
    "                # Add new binary feature name to headers\n",
    "                updated_headers.append(f\"{headers[col_idx]}_{category}_encoded\")\n",
    "        else:\n",
    "            # For non-categorical columns, add them directly\n",
    "            updated_data.append(data[:, col_idx])\n",
    "            updated_headers.append(headers[col_idx])\n",
    "\n",
    "    # Stack the updated data columns horizontally\n",
    "    updated_data = np.column_stack(updated_data)\n",
    "    return updated_data, updated_headers\n",
    "\n",
    "# Apply one-hot encoding on categorical features in x_train\n",
    "categorical_columns_filtered = [i for i, header in enumerate(x_train_headers_filtered) if header in categorical_features]\n",
    "\n",
    "x_train_encoded, x_train_encoded_headers = one_hot_encode(x_train_filtered, x_train_headers_filtered, categorical_columns_filtered)\n",
    "\n",
    "# Step 3: Display results\n",
    "print(\"Encoded dataset shape:\", x_train_encoded.shape)\n",
    "print(\"Encoded headers:\", x_train_encoded_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All checks passed: The dataset has only binary or continuous features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def verify_one_hot_encoding(data, binary_columns_indices):\n",
    "    \"\"\"\n",
    "    Verifies that all binary columns contain only 0s and 1s, and that all columns\n",
    "    in the dataset are either binary or continuous.\n",
    "\n",
    "    Args:\n",
    "        data (np.array): The dataset after one-hot encoding.\n",
    "        binary_columns_indices (list): List of indices of columns that should be binary.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if all checks pass, False otherwise.\n",
    "    \"\"\"\n",
    "    # Check binary columns\n",
    "    binary_check_passed = True\n",
    "    for col in binary_columns_indices:\n",
    "        unique_values = np.unique(data[:, col])\n",
    "        if not np.array_equal(unique_values, [0, 1]) and not np.array_equal(unique_values, [1, 0]):\n",
    "            print(f\"Check failed: Column {col} has values other than 0 and 1.\")\n",
    "            binary_check_passed = False\n",
    "\n",
    "    # Check non-binary columns are continuous\n",
    "    continuous_check_passed = True\n",
    "    for col in range(data.shape[1]):\n",
    "        if col not in binary_columns_indices:\n",
    "            unique_values = np.unique(data[:, col])\n",
    "            if len(unique_values) < 10:  # Continuous data should have a broad range of unique values\n",
    "                print(f\"Check failed: Column {col} appears to have low unique values, suggesting it may not be continuous.\")\n",
    "                continuous_check_passed = False\n",
    "\n",
    "    # Summary\n",
    "    if binary_check_passed and continuous_check_passed:\n",
    "        print(\"All checks passed: The dataset has only binary or continuous features.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"Some checks failed. Please review the warnings above.\")\n",
    "        return False\n",
    "\n",
    "# Example usage after one-hot encoding\n",
    "# Get the indices for original binary features\n",
    "original_binary_indices = [i for i, header in enumerate(x_train_encoded_headers) if header in binary_features]\n",
    "\n",
    "# Get the indices for one-hot encoded features\n",
    "one_hot_encoded_indices = [i for i, header in enumerate(x_train_encoded_headers) if \"_encoded\" in header]\n",
    "\n",
    "# Concatenate both lists to form the full list of binary column indices\n",
    "binary_columns_indices = original_binary_indices + one_hot_encoded_indices\n",
    "\n",
    "# Now use the combined binary_columns_indices to verify the dataset\n",
    "verify_one_hot_encoding(x_train_encoded, binary_columns_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Imputation methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Imputation (nice for normal distribution assumption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_imputation(data, binary_columns):\n",
    "    \"\"\"\n",
    "    Imputes missing values in the dataset by replacing them with the mean of each column.\n",
    "    For binary columns, the mean is rounded to 0 or 1.\n",
    "\n",
    "    Args:\n",
    "        data (np.array): The dataset with missing values (numpy array with NaN for missing values).\n",
    "        binary_columns (list): List of indices representing binary columns.\n",
    "\n",
    "    Returns:\n",
    "        np.array: The dataset with missing values replaced by column means or rounded means for binary features.\n",
    "    \"\"\"\n",
    "    col_means = np.nanmean(data, axis=0)\n",
    "    inds = np.where(np.isnan(data))\n",
    "    \n",
    "    # For binary columns, round the mean to 0 or 1\n",
    "    for col in binary_columns:\n",
    "        col_means[col] = round(col_means[col])\n",
    "\n",
    "    # Replace NaNs with the appropriate mean (rounded for binary columns)\n",
    "    data[inds] = np.take(col_means, inds[1])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify binary and continuous columns\n",
    "binary_columns_indices = [i for i, header in enumerate(x_train_encoded_headers) if \"_encoded\" in header or header in binary_features]\n",
    "continuous_columns_indices = [i for i in range(x_train_encoded.shape[1]) if i not in binary_columns_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Mean Imputation on the encoded dataset\n",
    "x_train_mean_imputed = mean_imputation(x_train_encoded.copy(), binary_columns=binary_columns_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: No missing values in the dataset.\n"
     ]
    }
   ],
   "source": [
    "if np.isnan(x_train_mean_imputed).any():\n",
    "    print(\"Warning: There are still missing values in the dataset after mean imputation.\")\n",
    "else:\n",
    "    print(\"Success: No missing values in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: All binary columns contain only 0s and 1s after mean imputation.\n"
     ]
    }
   ],
   "source": [
    "binary_columns_valid = True\n",
    "for col in binary_columns_indices:\n",
    "    unique_values = np.unique(x_train_mean_imputed[:, col])\n",
    "    if not np.array_equal(unique_values, [0, 1]) and not np.array_equal(unique_values, [1, 0]):\n",
    "        print(f\"Check failed: Column {col} has values other than 0 and 1.\")\n",
    "        binary_columns_valid = False\n",
    "\n",
    "if binary_columns_valid:\n",
    "    print(\"Success: All binary columns contain only 0s and 1s after mean imputation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: All continuous columns imputed correctly with mean values.\n"
     ]
    }
   ],
   "source": [
    "continuous_columns_valid = True\n",
    "for col in continuous_columns_indices:\n",
    "    mean_value = np.nanmean(x_train_encoded[:, col])  # Original mean (ignoring NaNs)\n",
    "    imputed_mean = np.mean(x_train_mean_imputed[:, col])  # Mean after imputation\n",
    "    if np.isclose(mean_value, imputed_mean, rtol=0.1):  # Allow slight tolerance due to rounding differences\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"Check failed: Column {col} imputed mean differs significantly from expected mean.\")\n",
    "        continuous_columns_valid = False\n",
    "\n",
    "if continuous_columns_valid:\n",
    "    print(\"Success: All continuous columns imputed correctly with mean values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape consistency check passed.\n"
     ]
    }
   ],
   "source": [
    "original_shape = x_train_encoded.shape\n",
    "imputed_shape = x_train_mean_imputed.shape\n",
    "if original_shape == imputed_shape:\n",
    "    print(\"Shape consistency check passed.\")\n",
    "else:\n",
    "    print(f\"Warning: Shape changed from {original_shape} to {imputed_shape} after imputation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 : Variance Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_thresholding(headers, data, threshold=0.01):\n",
    "    \"\"\"\n",
    "    Removes features that have variance below a specified threshold.\n",
    "\n",
    "    Args:\n",
    "        headers (list): The list of feature names.\n",
    "        data (np.array): The dataset (numpy array) with features as columns.\n",
    "        threshold (float): The minimum variance threshold (default is 1%).\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - valid_columns (list): The indices of the features that were kept.\n",
    "            - filtered_data (np.array): The filtered dataset with only the valid columns.\n",
    "    \"\"\"\n",
    "    # Compute variance for each column\n",
    "    variances = np.nanvar(data, axis=0)\n",
    "    valid_columns = np.where(variances >= threshold)[0]\n",
    "    removed_columns = np.where(variances < threshold)[0]\n",
    "\n",
    "    # Store the removed features\n",
    "    removed_features_names = [headers[i] for i in removed_columns]\n",
    "    removed_variance.extend(removed_features_names)\n",
    "    \n",
    "    # Log removed features\n",
    "    log_and_print_removals(headers, removed_columns, \"2: Variance Thresholding\", \"Low variance\")\n",
    "    \n",
    "    # Keep only columns with variance above the threshold\n",
    "    filtered_data = data[:, valid_columns]\n",
    "    return valid_columns, filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2: Variance Thresholding - Reason: Low variance:\n",
      "Removed 101 features: ['GENHLTH_7.0_encoded', 'GENHLTH_9.0_encoded', 'HLTHPLN1_7.0_encoded', 'HLTHPLN1_9.0_encoded', 'PERSDOC2_7.0_encoded', 'PERSDOC2_9.0_encoded', 'MEDCOST_7.0_encoded', 'MEDCOST_9.0_encoded', 'CHECKUP1_8.0_encoded', 'CHECKUP1_9.0_encoded', 'BPHIGH4_2.0_encoded', 'BPHIGH4_4.0_encoded', 'BPHIGH4_7.0_encoded', 'BPHIGH4_9.0_encoded', 'BLOODCHO_9.0_encoded', 'CHOLCHK_9.0_encoded', 'TOLDHI2_7.0_encoded', 'TOLDHI2_9.0_encoded', 'CVDSTRK3_7.0_encoded', 'CVDSTRK3_9.0_encoded', 'ASTHMA3_7.0_encoded', 'ASTHMA3_9.0_encoded', 'CHCSCNCR_7.0_encoded', 'CHCSCNCR_9.0_encoded', 'CHCOCNCR_7.0_encoded', 'CHCOCNCR_9.0_encoded', 'CHCCOPD1_7.0_encoded', 'CHCCOPD1_9.0_encoded', 'HAVARTH3_7.0_encoded', 'HAVARTH3_9.0_encoded', 'ADDEPEV2_7.0_encoded', 'ADDEPEV2_9.0_encoded', 'CHCKIDNY_7.0_encoded', 'CHCKIDNY_9.0_encoded', 'DIABETE3_2.0_encoded', 'DIABETE3_7.0_encoded', 'DIABETE3_9.0_encoded', 'MARITAL_9.0_encoded', 'EDUCA_1.0_encoded', 'EDUCA_9.0_encoded', 'RENTHOM1_7.0_encoded', 'RENTHOM1_9.0_encoded', 'VETERAN3_7.0_encoded', 'VETERAN3_9.0_encoded', 'EMPLOY1_9.0_encoded', 'INTERNET_7.0_encoded', 'INTERNET_9.0_encoded', 'QLACTLM2_7.0_encoded', 'QLACTLM2_9.0_encoded', 'USEEQUIP_7.0_encoded', 'USEEQUIP_9.0_encoded', 'BLIND_7.0_encoded', 'BLIND_9.0_encoded', 'DECIDE_7.0_encoded', 'DECIDE_9.0_encoded', 'DIFFWALK_7.0_encoded', 'DIFFWALK_9.0_encoded', 'DIFFDRES_7.0_encoded', 'DIFFDRES_9.0_encoded', 'DIFFALON_7.0_encoded', 'DIFFALON_9.0_encoded', 'SMOKE100_7.0_encoded', 'SMOKE100_9.0_encoded', 'USENOW3_7.0_encoded', 'USENOW3_9.0_encoded', 'EXERANY2_7.0_encoded', 'EXERANY2_9.0_encoded', 'SEATBELT_7.0_encoded', 'SEATBELT_8.0_encoded', 'SEATBELT_9.0_encoded', 'FLUSHOT6_7.0_encoded', 'FLUSHOT6_9.0_encoded', 'PNEUVAC3_9.0_encoded', 'HIVTST6_9.0_encoded', 'QSTVER_13.0_encoded', 'QSTLANG_3.0_encoded', '_RFHLTH_9.0_encoded', '_RFHYPE5_9.0_encoded', '_RFCHOL_9.0_encoded', '_LTASTH1_9.0_encoded', '_CASTHM1_9.0_encoded', '_ASTHMS1_9.0_encoded', '_PRACE1_5.0_encoded', '_PRACE1_7.0_encoded', '_PRACE1_8.0_encoded', '_PRACE1_77.0_encoded', '_MRACE1_5.0_encoded', '_MRACE1_77.0_encoded', '_HISPANC_9.0_encoded', '_RACE_5.0_encoded', '_RACE_6.0_encoded', '_CHLDCNT_6.0_encoded', '_CHLDCNT_9.0_encoded', '_EDUCAG_9.0_encoded', 'DRNKANY5_7.0_encoded', '_MISVEGN_2.0_encoded', '_MISVEGN_3.0_encoded', '_FRT16', '_VEG23', '_FRUITEX_2.0_encoded', '_VEGETEX_2.0_encoded']\n"
     ]
    }
   ],
   "source": [
    "# Apply the variance thresholding function\n",
    "valid_columns, x_train_variance_filtered = variance_thresholding(x_train_encoded_headers, x_train_mean_imputed)\n",
    "\n",
    "# Update headers to match the filtered dataset\n",
    "x_train_variance_filtered_headers = [x_train_encoded_headers[i] for i in valid_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_analysis(headers, x_data, y_data, low_threshold=0.05, high_threshold=0.9):\n",
    "    \"\"\"\n",
    "    Removes features that have low correlation with the outcome variable (y_data),\n",
    "    or that are highly correlated with other features.\n",
    "\n",
    "    Args:\n",
    "        headers (list): The list of feature names.\n",
    "        x_data (np.array): The feature dataset (numpy array) with features as columns.\n",
    "        y_data (np.array): The outcome variable (labels) to correlate with.\n",
    "        low_threshold (float): Minimum Pearson correlation threshold (default is 0.05).\n",
    "        high_threshold (float): Maximum Pearson correlation threshold (default is 0.9).\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - valid_columns (list): The indices of the features that were kept.\n",
    "            - filtered_data (np.array): The filtered dataset with only the valid columns.\n",
    "    \"\"\"\n",
    "    valid_columns = []\n",
    "    removed_columns = []\n",
    "\n",
    "    # Ensure feature and outcome have the same non-NaN indices\n",
    "    for i in range(x_data.shape[1]):\n",
    "        feature = x_data[:, i]\n",
    "\n",
    "        # Create a mask where both feature and y_data are non-NaN\n",
    "        non_nan_mask = ~np.isnan(feature) & ~np.isnan(y_data)\n",
    "\n",
    "        # Apply mask to both feature and y_data\n",
    "        feature_clean = feature[non_nan_mask]\n",
    "        y_data_clean = y_data[non_nan_mask]\n",
    "\n",
    "        # Compute correlation if both feature_clean and y_data_clean have enough data\n",
    "        if len(feature_clean) > 1 and len(y_data_clean) > 1:\n",
    "            correlation = np.corrcoef(feature_clean, y_data_clean)[0, 1]\n",
    "\n",
    "            # Check if the correlation is within the desired range\n",
    "            if abs(correlation) >= low_threshold and abs(correlation) <= high_threshold:\n",
    "                valid_columns.append(i)\n",
    "            else:\n",
    "                removed_columns.append(i)\n",
    "        else:\n",
    "            removed_columns.append(i)\n",
    "\n",
    "    # Log removed features\n",
    "    log_and_print_removals(headers, removed_columns, \"3: Correlation Analysis\", \"Low or high correlation\")\n",
    "\n",
    "    # Store the removed features\n",
    "    removed_features_names = [headers[i] for i in removed_columns]\n",
    "    removed_correlation.extend(removed_features_names)\n",
    "\n",
    "    # Filter valid columns\n",
    "    filtered_data = x_data[:, valid_columns]\n",
    "    return valid_columns, filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3: Correlation Analysis - Reason: Low or high correlation:\n",
      "Removed 224 features: ['_STATE', 'FMONTH', 'IDATE', 'IMONTH', 'IDAY', 'IYEAR_2015.0_encoded', 'IYEAR_2016.0_encoded', 'DISPCODE_1100.0_encoded', 'DISPCODE_1200.0_encoded', 'GENHLTH_3.0_encoded', 'MENTHLTH', 'HLTHPLN1_1.0_encoded', 'HLTHPLN1_2.0_encoded', 'PERSDOC2_1.0_encoded', 'MEDCOST_1.0_encoded', 'MEDCOST_2.0_encoded', 'CHECKUP1_2.0_encoded', 'CHECKUP1_3.0_encoded', 'CHECKUP1_4.0_encoded', 'CHECKUP1_7.0_encoded', 'BLOODCHO_7.0_encoded', 'CHOLCHK_4.0_encoded', 'CHOLCHK_7.0_encoded', 'ASTHMA3_1.0_encoded', 'DIABETE3_4.0_encoded', 'MARITAL_1.0_encoded', 'MARITAL_2.0_encoded', 'MARITAL_4.0_encoded', 'MARITAL_6.0_encoded', 'EDUCA_2.0_encoded', 'EDUCA_3.0_encoded', 'EDUCA_4.0_encoded', 'EDUCA_5.0_encoded', 'RENTHOM1_1.0_encoded', 'RENTHOM1_2.0_encoded', 'RENTHOM1_3.0_encoded', 'EMPLOY1_2.0_encoded', 'EMPLOY1_3.0_encoded', 'EMPLOY1_4.0_encoded', 'EMPLOY1_5.0_encoded', 'EMPLOY1_6.0_encoded', 'INCOME2_1.0_encoded', 'INCOME2_3.0_encoded', 'INCOME2_4.0_encoded', 'INCOME2_5.0_encoded', 'INCOME2_6.0_encoded', 'INCOME2_7.0_encoded', 'INCOME2_77.0_encoded', 'INCOME2_99.0_encoded', 'WEIGHT2', 'HEIGHT3', 'USENOW3_1.0_encoded', 'USENOW3_2.0_encoded', 'USENOW3_3.0_encoded', 'FRUITJU1', 'FRUIT1', 'FVBEANS', 'FVGREEN', 'FVORANG', 'VEGETAB1', 'SEATBELT_1.0_encoded', 'SEATBELT_2.0_encoded', 'SEATBELT_3.0_encoded', 'SEATBELT_4.0_encoded', 'SEATBELT_5.0_encoded', 'HIVTST6_1.0_encoded', 'HIVTST6_2.0_encoded', 'HIVTST6_7.0_encoded', 'QSTVER_11.0_encoded', 'QSTVER_12.0_encoded', 'QSTVER_20.0_encoded', 'QSTVER_21.0_encoded', 'QSTVER_22.0_encoded', 'QSTVER_23.0_encoded', 'QSTLANG_1.0_encoded', 'QSTLANG_2.0_encoded', '_STSTR', '_STRWT', '_RAWRAKE', '_WT2RAKE', '_DUALUSE_1.0_encoded', '_DUALUSE_2.0_encoded', '_DUALUSE_9.0_encoded', '_LLCPWT', '_HCVU651_2.0_encoded', '_CHOLCHK_2.0_encoded', '_CHOLCHK_9.0_encoded', '_LTASTH1_2.0_encoded', '_ASTHMS1_2.0_encoded', '_PRACE1_1.0_encoded', '_PRACE1_2.0_encoded', '_PRACE1_3.0_encoded', '_PRACE1_4.0_encoded', '_PRACE1_6.0_encoded', '_PRACE1_99.0_encoded', '_MRACE1_1.0_encoded', '_MRACE1_2.0_encoded', '_MRACE1_3.0_encoded', '_MRACE1_4.0_encoded', '_MRACE1_6.0_encoded', '_MRACE1_7.0_encoded', '_MRACE1_99.0_encoded', '_HISPANC_1.0_encoded', '_HISPANC_2.0_encoded', '_RACE_1.0_encoded', '_RACE_2.0_encoded', '_RACE_3.0_encoded', '_RACE_4.0_encoded', '_RACE_7.0_encoded', '_RACE_8.0_encoded', '_RACE_9.0_encoded', '_RACEG21_1.0_encoded', '_RACEG21_2.0_encoded', '_RACEG21_9.0_encoded', '_RACEGR3_1.0_encoded', '_RACEGR3_2.0_encoded', '_RACEGR3_3.0_encoded', '_RACEGR3_4.0_encoded', '_RACEGR3_5.0_encoded', '_RACEGR3_9.0_encoded', '_RACE_G1_1.0_encoded', '_RACE_G1_2.0_encoded', '_RACE_G1_3.0_encoded', '_RACE_G1_4.0_encoded', '_RACE_G1_5.0_encoded', '_AGE65YR_3.0_encoded', '_AGE_G_5.0_encoded', 'HTIN4', 'HTM4', '_BMI5CAT_1.0_encoded', '_BMI5CAT_2.0_encoded', '_BMI5CAT_3.0_encoded', '_RFBMI5_1.0_encoded', '_RFBMI5_9.0_encoded', '_CHLDCNT_4.0_encoded', '_CHLDCNT_5.0_encoded', '_EDUCAG_2.0_encoded', '_EDUCAG_3.0_encoded', '_INCOMG_3.0_encoded', '_INCOMG_4.0_encoded', '_INCOMG_9.0_encoded', '_SMOKER3_1.0_encoded', '_SMOKER3_2.0_encoded', '_SMOKER3_9.0_encoded', '_RFSMOK3_1.0_encoded', '_RFSMOK3_2.0_encoded', '_RFSMOK3_9.0_encoded', 'DRNKANY5_9.0_encoded', 'DROCDY3_', '_RFBING5_9.0_encoded', '_DRNKWEK', '_RFDRHV5_1.0_encoded', '_RFDRHV5_2.0_encoded', '_RFDRHV5_9.0_encoded', 'FTJUDA1_', 'FRUTDA1_', 'BEANDAY_', 'GRENDAY_', 'ORNGDAY_', 'VEGEDA1_', '_MISFRTN_0.0_encoded', '_MISFRTN_1.0_encoded', '_MISFRTN_2.0_encoded', '_MISVEGN_0.0_encoded', '_MISVEGN_1.0_encoded', '_MISVEGN_4.0_encoded', '_FRTRESP', '_VEGRESP', '_FRUTSUM', '_VEGESUM', '_FRTLT1_1.0_encoded', '_FRTLT1_2.0_encoded', '_FRTLT1_9.0_encoded', '_VEGLT1_1.0_encoded', '_VEGLT1_2.0_encoded', '_VEGLT1_9.0_encoded', '_FRUITEX_0.0_encoded', '_FRUITEX_1.0_encoded', '_VEGETEX_0.0_encoded', '_VEGETEX_1.0_encoded', '_TOTINDA_9.0_encoded', 'MAXVO2_', 'FC60_', 'STRFREQ_', 'PAMISS1__0.0_encoded', 'PAMISS1__1.0_encoded', 'PAMISS1__9.0_encoded', '_PACAT1_1.0_encoded', '_PACAT1_2.0_encoded', '_PACAT1_3.0_encoded', '_PACAT1_9.0_encoded', '_PAINDX1_1.0_encoded', '_PAINDX1_2.0_encoded', '_PAINDX1_9.0_encoded', '_PA150R2_1.0_encoded', '_PA150R2_2.0_encoded', '_PA150R2_9.0_encoded', '_PA300R2_1.0_encoded', '_PA300R2_9.0_encoded', '_PA30021_1.0_encoded', '_PA30021_2.0_encoded', '_PA30021_9.0_encoded', '_PASTRNG_1.0_encoded', '_PASTRNG_2.0_encoded', '_PASTRNG_9.0_encoded', '_PAREC1_1.0_encoded', '_PAREC1_2.0_encoded', '_PAREC1_3.0_encoded', '_PAREC1_4.0_encoded', '_PAREC1_9.0_encoded', '_PASTAE1_1.0_encoded', '_PASTAE1_2.0_encoded', '_PASTAE1_9.0_encoded', '_LMTACT1_9.0_encoded', '_LMTSCL1_9.0_encoded', '_RFSEAT2_1.0_encoded', '_RFSEAT2_2.0_encoded', '_RFSEAT2_9.0_encoded', '_RFSEAT3_1.0_encoded', '_RFSEAT3_2.0_encoded', '_RFSEAT3_9.0_encoded', '_AIDTST3_1.0_encoded', '_AIDTST3_2.0_encoded', '_AIDTST3_9.0_encoded']\n"
     ]
    }
   ],
   "source": [
    "# Apply the correlation analysis function\n",
    "valid_columns, x_train_correlation_filtered = correlation_analysis(x_train_variance_filtered_headers, x_train_variance_filtered, y_train)\n",
    "\n",
    "# Update headers to match the filtered dataset\n",
    "x_train_correlation_filtered_headers = [x_train_variance_filtered_headers[i] for i in valid_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train_correlation_filtered_headers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Statistical test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistical_test_analysis(headers, x_data, y_data, p_value_threshold=0.05):\n",
    "    \"\"\"\n",
    "    Retains features that have a statistically significant association with the outcome variable (y_data),\n",
    "    using an F-test for continuous features and a Chi-Square test for categorical features.\n",
    "\n",
    "    Args:\n",
    "        headers (list): The list of feature names.\n",
    "        x_data (np.array): The feature dataset (numpy array) with features as columns.\n",
    "        y_data (np.array): The outcome variable (labels) to test associations with.\n",
    "        p_value_threshold (float): The significance level threshold for retaining features (default is 0.05).\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - valid_columns (list): The indices of the features that were kept.\n",
    "            - filtered_data (np.array): The filtered dataset with only the valid columns.\n",
    "    \"\"\"\n",
    "    valid_columns = []\n",
    "    removed_columns = []\n",
    "\n",
    "    # Iterate over each feature\n",
    "    for i in range(x_data.shape[1]):\n",
    "        feature = x_data[:, i]\n",
    "        \n",
    "        # Create a mask where both feature and y_data are non-NaN\n",
    "        non_nan_mask = ~np.isnan(feature) & ~np.isnan(y_data)\n",
    "        feature_clean = feature[non_nan_mask]\n",
    "        y_data_clean = y_data[non_nan_mask]\n",
    "\n",
    "        # Check if the feature is continuous or categorical\n",
    "        unique_vals = np.unique(feature_clean)\n",
    "        if len(unique_vals) > 10:  # Assume continuous if more than 10 unique values\n",
    "            # Perform F-test for continuous features\n",
    "            classes = [feature_clean[y_data_clean == label] for label in np.unique(y_data_clean)]\n",
    "            overall_var = np.var(feature_clean)\n",
    "            between_group_var = np.var([np.mean(cls) for cls in classes])\n",
    "            f_statistic = between_group_var / overall_var if overall_var != 0 else 0\n",
    "            \n",
    "            # Calculate p-value approximation based on F-statistic\n",
    "            p_value = 1 - (1 / (1 + f_statistic))  # Simplified approximation\n",
    "\n",
    "        else:\n",
    "            # Perform Chi-Square test for categorical features\n",
    "            unique_y = np.unique(y_data_clean)\n",
    "            contingency_table = np.array([[(feature_clean == val).sum() & (y_data_clean == label).sum() for label in unique_y] for val in unique_vals])\n",
    "            chi_square_statistic = np.sum((contingency_table - np.mean(contingency_table))**2 / np.mean(contingency_table))\n",
    "            p_value = 1 - (1 / (1 + chi_square_statistic))  # Simplified approximation\n",
    "\n",
    "        # Determine if the feature is statistically significant\n",
    "        if p_value < p_value_threshold:\n",
    "            valid_columns.append(i)\n",
    "        else:\n",
    "            removed_columns.append(i)\n",
    "\n",
    "    # Log removed features\n",
    "    log_and_print_removals(headers, removed_columns, \"4: Statistical Test Analysis\", \"Not statistically significant\")\n",
    "\n",
    "    # Filter valid columns\n",
    "    filtered_data = x_data[:, valid_columns]\n",
    "    return valid_columns, filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train_variance_filtered_headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4: Statistical Test Analysis - Reason: Not statistically significant:\n",
      "Removed 320 features: ['IYEAR_2015.0_encoded', 'IYEAR_2016.0_encoded', 'DISPCODE_1100.0_encoded', 'DISPCODE_1200.0_encoded', 'GENHLTH_1.0_encoded', 'GENHLTH_2.0_encoded', 'GENHLTH_3.0_encoded', 'GENHLTH_4.0_encoded', 'GENHLTH_5.0_encoded', 'HLTHPLN1_1.0_encoded', 'HLTHPLN1_2.0_encoded', 'PERSDOC2_1.0_encoded', 'PERSDOC2_2.0_encoded', 'PERSDOC2_3.0_encoded', 'MEDCOST_1.0_encoded', 'MEDCOST_2.0_encoded', 'CHECKUP1_1.0_encoded', 'CHECKUP1_2.0_encoded', 'CHECKUP1_3.0_encoded', 'CHECKUP1_4.0_encoded', 'CHECKUP1_7.0_encoded', 'BPHIGH4_1.0_encoded', 'BPHIGH4_3.0_encoded', 'BLOODCHO_1.0_encoded', 'BLOODCHO_2.0_encoded', 'BLOODCHO_7.0_encoded', 'CHOLCHK_1.0_encoded', 'CHOLCHK_2.0_encoded', 'CHOLCHK_3.0_encoded', 'CHOLCHK_4.0_encoded', 'CHOLCHK_7.0_encoded', 'TOLDHI2_1.0_encoded', 'TOLDHI2_2.0_encoded', 'CVDSTRK3_1.0_encoded', 'CVDSTRK3_2.0_encoded', 'ASTHMA3_1.0_encoded', 'ASTHMA3_2.0_encoded', 'CHCSCNCR_1.0_encoded', 'CHCSCNCR_2.0_encoded', 'CHCOCNCR_1.0_encoded', 'CHCOCNCR_2.0_encoded', 'CHCCOPD1_1.0_encoded', 'CHCCOPD1_2.0_encoded', 'HAVARTH3_1.0_encoded', 'HAVARTH3_2.0_encoded', 'ADDEPEV2_1.0_encoded', 'ADDEPEV2_2.0_encoded', 'CHCKIDNY_1.0_encoded', 'CHCKIDNY_2.0_encoded', 'DIABETE3_1.0_encoded', 'DIABETE3_3.0_encoded', 'DIABETE3_4.0_encoded', 'SEX_1.0_encoded', 'SEX_2.0_encoded', 'MARITAL_1.0_encoded', 'MARITAL_2.0_encoded', 'MARITAL_3.0_encoded', 'MARITAL_4.0_encoded', 'MARITAL_5.0_encoded', 'MARITAL_6.0_encoded', 'EDUCA_2.0_encoded', 'EDUCA_3.0_encoded', 'EDUCA_4.0_encoded', 'EDUCA_5.0_encoded', 'EDUCA_6.0_encoded', 'RENTHOM1_1.0_encoded', 'RENTHOM1_2.0_encoded', 'RENTHOM1_3.0_encoded', 'VETERAN3_1.0_encoded', 'VETERAN3_2.0_encoded', 'EMPLOY1_1.0_encoded', 'EMPLOY1_2.0_encoded', 'EMPLOY1_3.0_encoded', 'EMPLOY1_4.0_encoded', 'EMPLOY1_5.0_encoded', 'EMPLOY1_6.0_encoded', 'EMPLOY1_7.0_encoded', 'EMPLOY1_8.0_encoded', 'INCOME2_1.0_encoded', 'INCOME2_2.0_encoded', 'INCOME2_3.0_encoded', 'INCOME2_4.0_encoded', 'INCOME2_5.0_encoded', 'INCOME2_6.0_encoded', 'INCOME2_7.0_encoded', 'INCOME2_8.0_encoded', 'INCOME2_77.0_encoded', 'INCOME2_99.0_encoded', 'INTERNET_1.0_encoded', 'INTERNET_2.0_encoded', 'QLACTLM2_1.0_encoded', 'QLACTLM2_2.0_encoded', 'USEEQUIP_1.0_encoded', 'USEEQUIP_2.0_encoded', 'BLIND_1.0_encoded', 'BLIND_2.0_encoded', 'DECIDE_1.0_encoded', 'DECIDE_2.0_encoded', 'DIFFWALK_1.0_encoded', 'DIFFWALK_2.0_encoded', 'DIFFDRES_1.0_encoded', 'DIFFDRES_2.0_encoded', 'DIFFALON_1.0_encoded', 'DIFFALON_2.0_encoded', 'SMOKE100_1.0_encoded', 'SMOKE100_2.0_encoded', 'USENOW3_1.0_encoded', 'USENOW3_2.0_encoded', 'USENOW3_3.0_encoded', 'EXERANY2_1.0_encoded', 'EXERANY2_2.0_encoded', 'SEATBELT_1.0_encoded', 'SEATBELT_2.0_encoded', 'SEATBELT_3.0_encoded', 'SEATBELT_4.0_encoded', 'SEATBELT_5.0_encoded', 'FLUSHOT6_1.0_encoded', 'FLUSHOT6_2.0_encoded', 'PNEUVAC3_1.0_encoded', 'PNEUVAC3_2.0_encoded', 'PNEUVAC3_7.0_encoded', 'HIVTST6_1.0_encoded', 'HIVTST6_2.0_encoded', 'HIVTST6_7.0_encoded', 'QSTVER_10.0_encoded', 'QSTVER_11.0_encoded', 'QSTVER_12.0_encoded', 'QSTVER_20.0_encoded', 'QSTVER_21.0_encoded', 'QSTVER_22.0_encoded', 'QSTVER_23.0_encoded', 'QSTLANG_1.0_encoded', 'QSTLANG_2.0_encoded', '_DUALUSE_1.0_encoded', '_DUALUSE_2.0_encoded', '_DUALUSE_9.0_encoded', '_RFHLTH_1.0_encoded', '_RFHLTH_2.0_encoded', '_HCVU651_1.0_encoded', '_HCVU651_2.0_encoded', '_HCVU651_9.0_encoded', '_RFHYPE5_1.0_encoded', '_RFHYPE5_2.0_encoded', '_CHOLCHK_1.0_encoded', '_CHOLCHK_2.0_encoded', '_CHOLCHK_3.0_encoded', '_CHOLCHK_9.0_encoded', '_RFCHOL_1.0_encoded', '_RFCHOL_2.0_encoded', '_LTASTH1_1.0_encoded', '_LTASTH1_2.0_encoded', '_CASTHM1_1.0_encoded', '_CASTHM1_2.0_encoded', '_ASTHMS1_1.0_encoded', '_ASTHMS1_2.0_encoded', '_ASTHMS1_3.0_encoded', '_DRDXAR1_1.0_encoded', '_DRDXAR1_2.0_encoded', '_PRACE1_1.0_encoded', '_PRACE1_2.0_encoded', '_PRACE1_3.0_encoded', '_PRACE1_4.0_encoded', '_PRACE1_6.0_encoded', '_PRACE1_99.0_encoded', '_MRACE1_1.0_encoded', '_MRACE1_2.0_encoded', '_MRACE1_3.0_encoded', '_MRACE1_4.0_encoded', '_MRACE1_6.0_encoded', '_MRACE1_7.0_encoded', '_MRACE1_99.0_encoded', '_HISPANC_1.0_encoded', '_HISPANC_2.0_encoded', '_RACE_1.0_encoded', '_RACE_2.0_encoded', '_RACE_3.0_encoded', '_RACE_4.0_encoded', '_RACE_7.0_encoded', '_RACE_8.0_encoded', '_RACE_9.0_encoded', '_RACEG21_1.0_encoded', '_RACEG21_2.0_encoded', '_RACEG21_9.0_encoded', '_RACEGR3_1.0_encoded', '_RACEGR3_2.0_encoded', '_RACEGR3_3.0_encoded', '_RACEGR3_4.0_encoded', '_RACEGR3_5.0_encoded', '_RACEGR3_9.0_encoded', '_RACE_G1_1.0_encoded', '_RACE_G1_2.0_encoded', '_RACE_G1_3.0_encoded', '_RACE_G1_4.0_encoded', '_RACE_G1_5.0_encoded', '_AGEG5YR', '_AGE65YR_1.0_encoded', '_AGE65YR_2.0_encoded', '_AGE65YR_3.0_encoded', '_AGE80', '_AGE_G_1.0_encoded', '_AGE_G_2.0_encoded', '_AGE_G_3.0_encoded', '_AGE_G_4.0_encoded', '_AGE_G_5.0_encoded', '_AGE_G_6.0_encoded', '_BMI5CAT_1.0_encoded', '_BMI5CAT_2.0_encoded', '_BMI5CAT_3.0_encoded', '_BMI5CAT_4.0_encoded', '_RFBMI5_1.0_encoded', '_RFBMI5_2.0_encoded', '_RFBMI5_9.0_encoded', '_CHLDCNT_1.0_encoded', '_CHLDCNT_2.0_encoded', '_CHLDCNT_3.0_encoded', '_CHLDCNT_4.0_encoded', '_CHLDCNT_5.0_encoded', '_EDUCAG_1.0_encoded', '_EDUCAG_2.0_encoded', '_EDUCAG_3.0_encoded', '_EDUCAG_4.0_encoded', '_INCOMG_1.0_encoded', '_INCOMG_2.0_encoded', '_INCOMG_3.0_encoded', '_INCOMG_4.0_encoded', '_INCOMG_5.0_encoded', '_INCOMG_9.0_encoded', '_SMOKER3_1.0_encoded', '_SMOKER3_2.0_encoded', '_SMOKER3_3.0_encoded', '_SMOKER3_4.0_encoded', '_SMOKER3_9.0_encoded', '_RFSMOK3_1.0_encoded', '_RFSMOK3_2.0_encoded', '_RFSMOK3_9.0_encoded', 'DRNKANY5_1.0_encoded', 'DRNKANY5_2.0_encoded', 'DRNKANY5_9.0_encoded', '_RFBING5_1.0_encoded', '_RFBING5_2.0_encoded', '_RFBING5_9.0_encoded', '_RFDRHV5_1.0_encoded', '_RFDRHV5_2.0_encoded', '_RFDRHV5_9.0_encoded', '_MISFRTN_0.0_encoded', '_MISFRTN_1.0_encoded', '_MISFRTN_2.0_encoded', '_MISVEGN_0.0_encoded', '_MISVEGN_1.0_encoded', '_MISVEGN_4.0_encoded', '_FRTRESP', '_VEGRESP', '_FRTLT1_1.0_encoded', '_FRTLT1_2.0_encoded', '_FRTLT1_9.0_encoded', '_VEGLT1_1.0_encoded', '_VEGLT1_2.0_encoded', '_VEGLT1_9.0_encoded', '_FRUITEX_0.0_encoded', '_FRUITEX_1.0_encoded', '_VEGETEX_0.0_encoded', '_VEGETEX_1.0_encoded', '_TOTINDA_1.0_encoded', '_TOTINDA_2.0_encoded', '_TOTINDA_9.0_encoded', 'PAMISS1__0.0_encoded', 'PAMISS1__1.0_encoded', 'PAMISS1__9.0_encoded', '_PACAT1_1.0_encoded', '_PACAT1_2.0_encoded', '_PACAT1_3.0_encoded', '_PACAT1_4.0_encoded', '_PACAT1_9.0_encoded', '_PAINDX1_1.0_encoded', '_PAINDX1_2.0_encoded', '_PAINDX1_9.0_encoded', '_PA150R2_1.0_encoded', '_PA150R2_2.0_encoded', '_PA150R2_3.0_encoded', '_PA150R2_9.0_encoded', '_PA300R2_1.0_encoded', '_PA300R2_2.0_encoded', '_PA300R2_3.0_encoded', '_PA300R2_9.0_encoded', '_PA30021_1.0_encoded', '_PA30021_2.0_encoded', '_PA30021_9.0_encoded', '_PASTRNG_1.0_encoded', '_PASTRNG_2.0_encoded', '_PASTRNG_9.0_encoded', '_PAREC1_1.0_encoded', '_PAREC1_2.0_encoded', '_PAREC1_3.0_encoded', '_PAREC1_4.0_encoded', '_PAREC1_9.0_encoded', '_PASTAE1_1.0_encoded', '_PASTAE1_2.0_encoded', '_PASTAE1_9.0_encoded', '_LMTACT1_1.0_encoded', '_LMTACT1_2.0_encoded', '_LMTACT1_3.0_encoded', '_LMTACT1_9.0_encoded', '_LMTWRK1_1.0_encoded', '_LMTWRK1_2.0_encoded', '_LMTWRK1_3.0_encoded', '_LMTWRK1_9.0_encoded', '_LMTSCL1_1.0_encoded', '_LMTSCL1_2.0_encoded', '_LMTSCL1_3.0_encoded', '_LMTSCL1_4.0_encoded', '_LMTSCL1_9.0_encoded', '_RFSEAT2_1.0_encoded', '_RFSEAT2_2.0_encoded', '_RFSEAT2_9.0_encoded', '_RFSEAT3_1.0_encoded', '_RFSEAT3_2.0_encoded', '_RFSEAT3_9.0_encoded', '_AIDTST3_1.0_encoded', '_AIDTST3_2.0_encoded', '_AIDTST3_9.0_encoded']\n",
      "Filtered dataset shape after statistical analysis: (328135, 42)\n",
      "Remaining features: ['_STATE', 'FMONTH', 'IDATE', 'IMONTH', 'IDAY', 'SEQNO', '_PSU', 'PHYSHLTH', 'MENTHLTH', 'CHILDREN', 'WEIGHT2', 'HEIGHT3', 'ALCDAY5', 'FRUITJU1', 'FRUIT1', 'FVBEANS', 'FVGREEN', 'FVORANG', 'VEGETAB1', 'STRENGTH', '_STSTR', '_STRWT', '_RAWRAKE', '_WT2RAKE', '_LLCPWT', 'HTIN4', 'HTM4', 'WTKG3', '_BMI5', 'DROCDY3_', '_DRNKWEK', 'FTJUDA1_', 'FRUTDA1_', 'BEANDAY_', 'GRENDAY_', 'ORNGDAY_', 'VEGEDA1_', '_FRUTSUM', '_VEGESUM', 'MAXVO2_', 'FC60_', 'STRFREQ_']\n",
      "Removed features due to lack of statistical significance: []\n"
     ]
    }
   ],
   "source": [
    "# Applying the statistical test analysis to the dataset after correlation analysis\n",
    "removed_statistical = []  # List to store names of removed statistically insignificant features\n",
    "valid_columns, x_train_statistical_filtered = statistical_test_analysis(x_train_variance_filtered_headers, x_train_variance_filtered, y_train)\n",
    "\n",
    "# Update headers to match the filtered dataset\n",
    "x_train_statistical_filtered_headers = [x_train_variance_filtered_headers[i] for i in valid_columns]\n",
    "\n",
    "# Display results\n",
    "print(\"Filtered dataset shape after statistical analysis:\", x_train_statistical_filtered.shape)\n",
    "print(\"Remaining features:\", x_train_statistical_filtered_headers)\n",
    "print(\"Removed features due to lack of statistical significance:\", removed_statistical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train_statistical_filtered_headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removal Log:\n",
      "CTELENUM removed at 1: Remove Missing Values: Too many missing values\n",
      "PVTRESD1 removed at 1: Remove Missing Values: Too many missing values\n",
      "COLGHOUS removed at 1: Remove Missing Values: Too many missing values\n",
      "STATERES removed at 1: Remove Missing Values: Too many missing values\n",
      "CELLFON3 removed at 1: Remove Missing Values: Too many missing values\n",
      "LADULT removed at 1: Remove Missing Values: Too many missing values\n",
      "NUMADULT removed at 1: Remove Missing Values: Too many missing values\n",
      "NUMMEN removed at 1: Remove Missing Values: Too many missing values\n",
      "NUMWOMEN removed at 1: Remove Missing Values: Too many missing values\n",
      "CTELNUM1 removed at 1: Remove Missing Values: Too many missing values\n",
      "CELLFON2 removed at 1: Remove Missing Values: Too many missing values\n",
      "CADULT removed at 1: Remove Missing Values: Too many missing values\n",
      "PVTRESD2 removed at 1: Remove Missing Values: Too many missing values\n",
      "CCLGHOUS removed at 1: Remove Missing Values: Too many missing values\n",
      "CSTATE removed at 1: Remove Missing Values: Too many missing values\n",
      "LANDLINE removed at 1: Remove Missing Values: Too many missing values\n",
      "HHADULT removed at 1: Remove Missing Values: Too many missing values\n",
      "POORHLTH removed at 1: Remove Missing Values: Too many missing values\n",
      "BPMEDS removed at 1: Remove Missing Values: Too many missing values\n",
      "ASTHNOW removed at 1: Remove Missing Values: Too many missing values\n",
      "DIABAGE2 removed at 1: Remove Missing Values: Too many missing values\n",
      "NUMHHOL2 removed at 1: Remove Missing Values: Too many missing values\n",
      "NUMPHON2 removed at 1: Remove Missing Values: Too many missing values\n",
      "CPDEMO1 removed at 1: Remove Missing Values: Too many missing values\n",
      "PREGNANT removed at 1: Remove Missing Values: Too many missing values\n",
      "SMOKDAY2 removed at 1: Remove Missing Values: Too many missing values\n",
      "STOPSMK2 removed at 1: Remove Missing Values: Too many missing values\n",
      "LASTSMK2 removed at 1: Remove Missing Values: Too many missing values\n",
      "AVEDRNK2 removed at 1: Remove Missing Values: Too many missing values\n",
      "DRNK3GE5 removed at 1: Remove Missing Values: Too many missing values\n",
      "MAXDRNKS removed at 1: Remove Missing Values: Too many missing values\n",
      "EXRACT11 removed at 1: Remove Missing Values: Too many missing values\n",
      "EXEROFT1 removed at 1: Remove Missing Values: Too many missing values\n",
      "EXERHMM1 removed at 1: Remove Missing Values: Too many missing values\n",
      "EXRACT21 removed at 1: Remove Missing Values: Too many missing values\n",
      "EXEROFT2 removed at 1: Remove Missing Values: Too many missing values\n",
      "EXERHMM2 removed at 1: Remove Missing Values: Too many missing values\n",
      "LMTJOIN3 removed at 1: Remove Missing Values: Too many missing values\n",
      "ARTHDIS2 removed at 1: Remove Missing Values: Too many missing values\n",
      "ARTHSOCL removed at 1: Remove Missing Values: Too many missing values\n",
      "JOINPAIN removed at 1: Remove Missing Values: Too many missing values\n",
      "FLSHTMY2 removed at 1: Remove Missing Values: Too many missing values\n",
      "IMFVPLAC removed at 1: Remove Missing Values: Too many missing values\n",
      "HIVTSTD3 removed at 1: Remove Missing Values: Too many missing values\n",
      "WHRTST10 removed at 1: Remove Missing Values: Too many missing values\n",
      "PDIABTST removed at 1: Remove Missing Values: Too many missing values\n",
      "PREDIAB1 removed at 1: Remove Missing Values: Too many missing values\n",
      "INSULIN removed at 1: Remove Missing Values: Too many missing values\n",
      "BLDSUGAR removed at 1: Remove Missing Values: Too many missing values\n",
      "FEETCHK2 removed at 1: Remove Missing Values: Too many missing values\n",
      "DOCTDIAB removed at 1: Remove Missing Values: Too many missing values\n",
      "CHKHEMO3 removed at 1: Remove Missing Values: Too many missing values\n",
      "FEETCHK removed at 1: Remove Missing Values: Too many missing values\n",
      "EYEEXAM removed at 1: Remove Missing Values: Too many missing values\n",
      "DIABEYE removed at 1: Remove Missing Values: Too many missing values\n",
      "DIABEDU removed at 1: Remove Missing Values: Too many missing values\n",
      "CAREGIV1 removed at 1: Remove Missing Values: Too many missing values\n",
      "CRGVREL1 removed at 1: Remove Missing Values: Too many missing values\n",
      "CRGVLNG1 removed at 1: Remove Missing Values: Too many missing values\n",
      "CRGVHRS1 removed at 1: Remove Missing Values: Too many missing values\n",
      "CRGVPRB1 removed at 1: Remove Missing Values: Too many missing values\n",
      "CRGVPERS removed at 1: Remove Missing Values: Too many missing values\n",
      "CRGVHOUS removed at 1: Remove Missing Values: Too many missing values\n",
      "CRGVMST2 removed at 1: Remove Missing Values: Too many missing values\n",
      "CRGVEXPT removed at 1: Remove Missing Values: Too many missing values\n",
      "VIDFCLT2 removed at 1: Remove Missing Values: Too many missing values\n",
      "VIREDIF3 removed at 1: Remove Missing Values: Too many missing values\n",
      "VIPRFVS2 removed at 1: Remove Missing Values: Too many missing values\n",
      "VINOCRE2 removed at 1: Remove Missing Values: Too many missing values\n",
      "VIEYEXM2 removed at 1: Remove Missing Values: Too many missing values\n",
      "VIINSUR2 removed at 1: Remove Missing Values: Too many missing values\n",
      "VICTRCT4 removed at 1: Remove Missing Values: Too many missing values\n",
      "VIGLUMA2 removed at 1: Remove Missing Values: Too many missing values\n",
      "VIMACDG2 removed at 1: Remove Missing Values: Too many missing values\n",
      "CIMEMLOS removed at 1: Remove Missing Values: Too many missing values\n",
      "CDHOUSE removed at 1: Remove Missing Values: Too many missing values\n",
      "CDASSIST removed at 1: Remove Missing Values: Too many missing values\n",
      "CDHELP removed at 1: Remove Missing Values: Too many missing values\n",
      "CDSOCIAL removed at 1: Remove Missing Values: Too many missing values\n",
      "CDDISCUS removed at 1: Remove Missing Values: Too many missing values\n",
      "WTCHSALT removed at 1: Remove Missing Values: Too many missing values\n",
      "LONGWTCH removed at 1: Remove Missing Values: Too many missing values\n",
      "DRADVISE removed at 1: Remove Missing Values: Too many missing values\n",
      "ASTHMAGE removed at 1: Remove Missing Values: Too many missing values\n",
      "ASATTACK removed at 1: Remove Missing Values: Too many missing values\n",
      "ASERVIST removed at 1: Remove Missing Values: Too many missing values\n",
      "ASDRVIST removed at 1: Remove Missing Values: Too many missing values\n",
      "ASRCHKUP removed at 1: Remove Missing Values: Too many missing values\n",
      "ASACTLIM removed at 1: Remove Missing Values: Too many missing values\n",
      "ASYMPTOM removed at 1: Remove Missing Values: Too many missing values\n",
      "ASNOSLEP removed at 1: Remove Missing Values: Too many missing values\n",
      "ASTHMED3 removed at 1: Remove Missing Values: Too many missing values\n",
      "ASINHALR removed at 1: Remove Missing Values: Too many missing values\n",
      "HAREHAB1 removed at 1: Remove Missing Values: Too many missing values\n",
      "STREHAB1 removed at 1: Remove Missing Values: Too many missing values\n",
      "CVDASPRN removed at 1: Remove Missing Values: Too many missing values\n",
      "ASPUNSAF removed at 1: Remove Missing Values: Too many missing values\n",
      "RLIVPAIN removed at 1: Remove Missing Values: Too many missing values\n",
      "RDUCHART removed at 1: Remove Missing Values: Too many missing values\n",
      "RDUCSTRK removed at 1: Remove Missing Values: Too many missing values\n",
      "ARTTODAY removed at 1: Remove Missing Values: Too many missing values\n",
      "ARTHWGT removed at 1: Remove Missing Values: Too many missing values\n",
      "ARTHEXER removed at 1: Remove Missing Values: Too many missing values\n",
      "ARTHEDU removed at 1: Remove Missing Values: Too many missing values\n",
      "TETANUS removed at 1: Remove Missing Values: Too many missing values\n",
      "HPVADVC2 removed at 1: Remove Missing Values: Too many missing values\n",
      "HPVADSHT removed at 1: Remove Missing Values: Too many missing values\n",
      "SHINGLE2 removed at 1: Remove Missing Values: Too many missing values\n",
      "HADMAM removed at 1: Remove Missing Values: Too many missing values\n",
      "HOWLONG removed at 1: Remove Missing Values: Too many missing values\n",
      "HADPAP2 removed at 1: Remove Missing Values: Too many missing values\n",
      "LASTPAP2 removed at 1: Remove Missing Values: Too many missing values\n",
      "HPVTEST removed at 1: Remove Missing Values: Too many missing values\n",
      "HPLSTTST removed at 1: Remove Missing Values: Too many missing values\n",
      "HADHYST2 removed at 1: Remove Missing Values: Too many missing values\n",
      "PROFEXAM removed at 1: Remove Missing Values: Too many missing values\n",
      "LENGEXAM removed at 1: Remove Missing Values: Too many missing values\n",
      "BLDSTOOL removed at 1: Remove Missing Values: Too many missing values\n",
      "LSTBLDS3 removed at 1: Remove Missing Values: Too many missing values\n",
      "HADSIGM3 removed at 1: Remove Missing Values: Too many missing values\n",
      "HADSGCO1 removed at 1: Remove Missing Values: Too many missing values\n",
      "LASTSIG3 removed at 1: Remove Missing Values: Too many missing values\n",
      "PCPSAAD2 removed at 1: Remove Missing Values: Too many missing values\n",
      "PCPSADI1 removed at 1: Remove Missing Values: Too many missing values\n",
      "PCPSARE1 removed at 1: Remove Missing Values: Too many missing values\n",
      "PSATEST1 removed at 1: Remove Missing Values: Too many missing values\n",
      "PSATIME removed at 1: Remove Missing Values: Too many missing values\n",
      "PCPSARS1 removed at 1: Remove Missing Values: Too many missing values\n",
      "PCPSADE1 removed at 1: Remove Missing Values: Too many missing values\n",
      "PCDMDECN removed at 1: Remove Missing Values: Too many missing values\n",
      "SCNTMNY1 removed at 1: Remove Missing Values: Too many missing values\n",
      "SCNTMEL1 removed at 1: Remove Missing Values: Too many missing values\n",
      "SCNTPAID removed at 1: Remove Missing Values: Too many missing values\n",
      "SCNTWRK1 removed at 1: Remove Missing Values: Too many missing values\n",
      "SCNTLPAD removed at 1: Remove Missing Values: Too many missing values\n",
      "SCNTLWK1 removed at 1: Remove Missing Values: Too many missing values\n",
      "SXORIENT removed at 1: Remove Missing Values: Too many missing values\n",
      "TRNSGNDR removed at 1: Remove Missing Values: Too many missing values\n",
      "RCSGENDR removed at 1: Remove Missing Values: Too many missing values\n",
      "RCSRLTN2 removed at 1: Remove Missing Values: Too many missing values\n",
      "CASTHDX2 removed at 1: Remove Missing Values: Too many missing values\n",
      "CASTHNO2 removed at 1: Remove Missing Values: Too many missing values\n",
      "EMTSUPRT removed at 1: Remove Missing Values: Too many missing values\n",
      "LSATISFY removed at 1: Remove Missing Values: Too many missing values\n",
      "ADPLEASR removed at 1: Remove Missing Values: Too many missing values\n",
      "ADDOWN removed at 1: Remove Missing Values: Too many missing values\n",
      "ADSLEEP removed at 1: Remove Missing Values: Too many missing values\n",
      "ADENERGY removed at 1: Remove Missing Values: Too many missing values\n",
      "ADEAT1 removed at 1: Remove Missing Values: Too many missing values\n",
      "ADFAIL removed at 1: Remove Missing Values: Too many missing values\n",
      "ADTHINK removed at 1: Remove Missing Values: Too many missing values\n",
      "ADMOVE removed at 1: Remove Missing Values: Too many missing values\n",
      "MISTMNT removed at 1: Remove Missing Values: Too many missing values\n",
      "ADANXEV removed at 1: Remove Missing Values: Too many missing values\n",
      "MSCODE removed at 1: Remove Missing Values: Too many missing values\n",
      "_CHISPNC removed at 1: Remove Missing Values: Too many missing values\n",
      "_CRACE1 removed at 1: Remove Missing Values: Too many missing values\n",
      "_CPRACE removed at 1: Remove Missing Values: Too many missing values\n",
      "_CLLCPWT removed at 1: Remove Missing Values: Too many missing values\n",
      "_DUALCOR removed at 1: Remove Missing Values: Too many missing values\n",
      "METVL11_ removed at 1: Remove Missing Values: Too many missing values\n",
      "METVL21_ removed at 1: Remove Missing Values: Too many missing values\n",
      "ACTIN11_ removed at 1: Remove Missing Values: Too many missing values\n",
      "ACTIN21_ removed at 1: Remove Missing Values: Too many missing values\n",
      "PADUR1_ removed at 1: Remove Missing Values: Too many missing values\n",
      "PADUR2_ removed at 1: Remove Missing Values: Too many missing values\n",
      "PAFREQ1_ removed at 1: Remove Missing Values: Too many missing values\n",
      "PAFREQ2_ removed at 1: Remove Missing Values: Too many missing values\n",
      "_MINAC11 removed at 1: Remove Missing Values: Too many missing values\n",
      "_MINAC21 removed at 1: Remove Missing Values: Too many missing values\n",
      "PAMIN11_ removed at 1: Remove Missing Values: Too many missing values\n",
      "PAMIN21_ removed at 1: Remove Missing Values: Too many missing values\n",
      "PA1MIN_ removed at 1: Remove Missing Values: Too many missing values\n",
      "PAVIG11_ removed at 1: Remove Missing Values: Too many missing values\n",
      "PAVIG21_ removed at 1: Remove Missing Values: Too many missing values\n",
      "PA1VIGM_ removed at 1: Remove Missing Values: Too many missing values\n",
      "_FLSHOT6 removed at 1: Remove Missing Values: Too many missing values\n",
      "_PNEUMO2 removed at 1: Remove Missing Values: Too many missing values\n",
      "GENHLTH_7.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "GENHLTH_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "HLTHPLN1_7.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "HLTHPLN1_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "PERSDOC2_7.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "PERSDOC2_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "MEDCOST_7.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "MEDCOST_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "CHECKUP1_8.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "CHECKUP1_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "BPHIGH4_2.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "BPHIGH4_4.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "BPHIGH4_7.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "BPHIGH4_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "BLOODCHO_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "CHOLCHK_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "TOLDHI2_7.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "TOLDHI2_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "CVDSTRK3_7.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "CVDSTRK3_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "ASTHMA3_7.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "ASTHMA3_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "CHCSCNCR_7.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "CHCSCNCR_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "CHCOCNCR_7.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "CHCOCNCR_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "CHCCOPD1_7.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "CHCCOPD1_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "HAVARTH3_7.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "HAVARTH3_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "ADDEPEV2_7.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "ADDEPEV2_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "CHCKIDNY_7.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "CHCKIDNY_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "DIABETE3_2.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "DIABETE3_7.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "DIABETE3_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "MARITAL_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "EDUCA_1.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "EDUCA_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "RENTHOM1_7.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "RENTHOM1_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "VETERAN3_7.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "VETERAN3_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "EMPLOY1_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "INTERNET_7.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "INTERNET_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "QLACTLM2_7.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "QLACTLM2_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "USEEQUIP_7.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "USEEQUIP_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "BLIND_7.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "BLIND_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "DECIDE_7.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "DECIDE_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "DIFFWALK_7.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "DIFFWALK_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "DIFFDRES_7.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "DIFFDRES_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "DIFFALON_7.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "DIFFALON_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "SMOKE100_7.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "SMOKE100_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "USENOW3_7.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "USENOW3_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "EXERANY2_7.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "EXERANY2_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "SEATBELT_7.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "SEATBELT_8.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "SEATBELT_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "FLUSHOT6_7.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "FLUSHOT6_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "PNEUVAC3_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "HIVTST6_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "QSTVER_13.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "QSTLANG_3.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "_RFHLTH_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "_RFHYPE5_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "_RFCHOL_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "_LTASTH1_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "_CASTHM1_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "_ASTHMS1_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "_PRACE1_5.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "_PRACE1_7.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "_PRACE1_8.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "_PRACE1_77.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "_MRACE1_5.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "_MRACE1_77.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "_HISPANC_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "_RACE_5.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "_RACE_6.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "_CHLDCNT_6.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "_CHLDCNT_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "_EDUCAG_9.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "DRNKANY5_7.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "_MISVEGN_2.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "_MISVEGN_3.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "_FRT16 removed at 2: Variance Thresholding: Low variance\n",
      "_VEG23 removed at 2: Variance Thresholding: Low variance\n",
      "_FRUITEX_2.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "_VEGETEX_2.0_encoded removed at 2: Variance Thresholding: Low variance\n",
      "_STATE removed at 3: Correlation Analysis: Low or high correlation\n",
      "FMONTH removed at 3: Correlation Analysis: Low or high correlation\n",
      "IDATE removed at 3: Correlation Analysis: Low or high correlation\n",
      "IMONTH removed at 3: Correlation Analysis: Low or high correlation\n",
      "IDAY removed at 3: Correlation Analysis: Low or high correlation\n",
      "IYEAR_2015.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "IYEAR_2016.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "DISPCODE_1100.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "DISPCODE_1200.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "GENHLTH_3.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "MENTHLTH removed at 3: Correlation Analysis: Low or high correlation\n",
      "HLTHPLN1_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "HLTHPLN1_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "PERSDOC2_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "MEDCOST_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "MEDCOST_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "CHECKUP1_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "CHECKUP1_3.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "CHECKUP1_4.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "CHECKUP1_7.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "BLOODCHO_7.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "CHOLCHK_4.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "CHOLCHK_7.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "ASTHMA3_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "DIABETE3_4.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "MARITAL_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "MARITAL_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "MARITAL_4.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "MARITAL_6.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "EDUCA_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "EDUCA_3.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "EDUCA_4.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "EDUCA_5.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "RENTHOM1_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "RENTHOM1_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "RENTHOM1_3.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "EMPLOY1_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "EMPLOY1_3.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "EMPLOY1_4.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "EMPLOY1_5.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "EMPLOY1_6.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "INCOME2_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "INCOME2_3.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "INCOME2_4.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "INCOME2_5.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "INCOME2_6.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "INCOME2_7.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "INCOME2_77.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "INCOME2_99.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "WEIGHT2 removed at 3: Correlation Analysis: Low or high correlation\n",
      "HEIGHT3 removed at 3: Correlation Analysis: Low or high correlation\n",
      "USENOW3_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "USENOW3_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "USENOW3_3.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "FRUITJU1 removed at 3: Correlation Analysis: Low or high correlation\n",
      "FRUIT1 removed at 3: Correlation Analysis: Low or high correlation\n",
      "FVBEANS removed at 3: Correlation Analysis: Low or high correlation\n",
      "FVGREEN removed at 3: Correlation Analysis: Low or high correlation\n",
      "FVORANG removed at 3: Correlation Analysis: Low or high correlation\n",
      "VEGETAB1 removed at 3: Correlation Analysis: Low or high correlation\n",
      "SEATBELT_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "SEATBELT_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "SEATBELT_3.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "SEATBELT_4.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "SEATBELT_5.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "HIVTST6_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "HIVTST6_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "HIVTST6_7.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "QSTVER_11.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "QSTVER_12.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "QSTVER_20.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "QSTVER_21.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "QSTVER_22.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "QSTVER_23.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "QSTLANG_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "QSTLANG_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_STSTR removed at 3: Correlation Analysis: Low or high correlation\n",
      "_STRWT removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RAWRAKE removed at 3: Correlation Analysis: Low or high correlation\n",
      "_WT2RAKE removed at 3: Correlation Analysis: Low or high correlation\n",
      "_DUALUSE_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_DUALUSE_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_DUALUSE_9.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_LLCPWT removed at 3: Correlation Analysis: Low or high correlation\n",
      "_HCVU651_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_CHOLCHK_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_CHOLCHK_9.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_LTASTH1_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_ASTHMS1_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PRACE1_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PRACE1_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PRACE1_3.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PRACE1_4.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PRACE1_6.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PRACE1_99.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_MRACE1_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_MRACE1_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_MRACE1_3.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_MRACE1_4.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_MRACE1_6.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_MRACE1_7.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_MRACE1_99.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_HISPANC_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_HISPANC_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RACE_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RACE_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RACE_3.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RACE_4.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RACE_7.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RACE_8.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RACE_9.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RACEG21_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RACEG21_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RACEG21_9.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RACEGR3_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RACEGR3_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RACEGR3_3.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RACEGR3_4.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RACEGR3_5.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RACEGR3_9.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RACE_G1_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RACE_G1_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RACE_G1_3.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RACE_G1_4.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RACE_G1_5.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_AGE65YR_3.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_AGE_G_5.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "HTIN4 removed at 3: Correlation Analysis: Low or high correlation\n",
      "HTM4 removed at 3: Correlation Analysis: Low or high correlation\n",
      "_BMI5CAT_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_BMI5CAT_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_BMI5CAT_3.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RFBMI5_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RFBMI5_9.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_CHLDCNT_4.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_CHLDCNT_5.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_EDUCAG_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_EDUCAG_3.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_INCOMG_3.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_INCOMG_4.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_INCOMG_9.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_SMOKER3_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_SMOKER3_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_SMOKER3_9.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RFSMOK3_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RFSMOK3_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RFSMOK3_9.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "DRNKANY5_9.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "DROCDY3_ removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RFBING5_9.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_DRNKWEK removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RFDRHV5_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RFDRHV5_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RFDRHV5_9.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "FTJUDA1_ removed at 3: Correlation Analysis: Low or high correlation\n",
      "FRUTDA1_ removed at 3: Correlation Analysis: Low or high correlation\n",
      "BEANDAY_ removed at 3: Correlation Analysis: Low or high correlation\n",
      "GRENDAY_ removed at 3: Correlation Analysis: Low or high correlation\n",
      "ORNGDAY_ removed at 3: Correlation Analysis: Low or high correlation\n",
      "VEGEDA1_ removed at 3: Correlation Analysis: Low or high correlation\n",
      "_MISFRTN_0.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_MISFRTN_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_MISFRTN_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_MISVEGN_0.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_MISVEGN_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_MISVEGN_4.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_FRTRESP removed at 3: Correlation Analysis: Low or high correlation\n",
      "_VEGRESP removed at 3: Correlation Analysis: Low or high correlation\n",
      "_FRUTSUM removed at 3: Correlation Analysis: Low or high correlation\n",
      "_VEGESUM removed at 3: Correlation Analysis: Low or high correlation\n",
      "_FRTLT1_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_FRTLT1_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_FRTLT1_9.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_VEGLT1_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_VEGLT1_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_VEGLT1_9.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_FRUITEX_0.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_FRUITEX_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_VEGETEX_0.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_VEGETEX_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_TOTINDA_9.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "MAXVO2_ removed at 3: Correlation Analysis: Low or high correlation\n",
      "FC60_ removed at 3: Correlation Analysis: Low or high correlation\n",
      "STRFREQ_ removed at 3: Correlation Analysis: Low or high correlation\n",
      "PAMISS1__0.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "PAMISS1__1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "PAMISS1__9.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PACAT1_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PACAT1_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PACAT1_3.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PACAT1_9.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PAINDX1_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PAINDX1_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PAINDX1_9.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PA150R2_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PA150R2_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PA150R2_9.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PA300R2_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PA300R2_9.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PA30021_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PA30021_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PA30021_9.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PASTRNG_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PASTRNG_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PASTRNG_9.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PAREC1_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PAREC1_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PAREC1_3.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PAREC1_4.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PAREC1_9.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PASTAE1_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PASTAE1_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_PASTAE1_9.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_LMTACT1_9.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_LMTSCL1_9.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RFSEAT2_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RFSEAT2_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RFSEAT2_9.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RFSEAT3_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RFSEAT3_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_RFSEAT3_9.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_AIDTST3_1.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_AIDTST3_2.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "_AIDTST3_9.0_encoded removed at 3: Correlation Analysis: Low or high correlation\n",
      "Preprocessing complete. Cleaned dataset saved as 'cleaned_dataset.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Print the final removal log for interpretability\n",
    "print(\"\\nRemoval Log:\")\n",
    "for entry in removal_log:\n",
    "    print(entry)\n",
    "\n",
    "print(\"Preprocessing complete. Cleaned dataset saved as 'cleaned_dataset.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CTELENUM', 'PVTRESD1', 'COLGHOUS', 'STATERES', 'CELLFON3', 'LADULT', 'NUMADULT', 'NUMMEN', 'NUMWOMEN', 'CTELNUM1', 'CELLFON2', 'CADULT', 'PVTRESD2', 'CCLGHOUS', 'CSTATE', 'LANDLINE', 'HHADULT', 'POORHLTH', 'BPMEDS', 'ASTHNOW', 'DIABAGE2', 'NUMHHOL2', 'NUMPHON2', 'CPDEMO1', 'PREGNANT', 'SMOKDAY2', 'STOPSMK2', 'LASTSMK2', 'AVEDRNK2', 'DRNK3GE5', 'MAXDRNKS', 'EXRACT11', 'EXEROFT1', 'EXERHMM1', 'EXRACT21', 'EXEROFT2', 'EXERHMM2', 'LMTJOIN3', 'ARTHDIS2', 'ARTHSOCL', 'JOINPAIN', 'FLSHTMY2', 'IMFVPLAC', 'HIVTSTD3', 'WHRTST10', 'PDIABTST', 'PREDIAB1', 'INSULIN', 'BLDSUGAR', 'FEETCHK2', 'DOCTDIAB', 'CHKHEMO3', 'FEETCHK', 'EYEEXAM', 'DIABEYE', 'DIABEDU', 'CAREGIV1', 'CRGVREL1', 'CRGVLNG1', 'CRGVHRS1', 'CRGVPRB1', 'CRGVPERS', 'CRGVHOUS', 'CRGVMST2', 'CRGVEXPT', 'VIDFCLT2', 'VIREDIF3', 'VIPRFVS2', 'VINOCRE2', 'VIEYEXM2', 'VIINSUR2', 'VICTRCT4', 'VIGLUMA2', 'VIMACDG2', 'CIMEMLOS', 'CDHOUSE', 'CDASSIST', 'CDHELP', 'CDSOCIAL', 'CDDISCUS', 'WTCHSALT', 'LONGWTCH', 'DRADVISE', 'ASTHMAGE', 'ASATTACK', 'ASERVIST', 'ASDRVIST', 'ASRCHKUP', 'ASACTLIM', 'ASYMPTOM', 'ASNOSLEP', 'ASTHMED3', 'ASINHALR', 'HAREHAB1', 'STREHAB1', 'CVDASPRN', 'ASPUNSAF', 'RLIVPAIN', 'RDUCHART', 'RDUCSTRK', 'ARTTODAY', 'ARTHWGT', 'ARTHEXER', 'ARTHEDU', 'TETANUS', 'HPVADVC2', 'HPVADSHT', 'SHINGLE2', 'HADMAM', 'HOWLONG', 'HADPAP2', 'LASTPAP2', 'HPVTEST', 'HPLSTTST', 'HADHYST2', 'PROFEXAM', 'LENGEXAM', 'BLDSTOOL', 'LSTBLDS3', 'HADSIGM3', 'HADSGCO1', 'LASTSIG3', 'PCPSAAD2', 'PCPSADI1', 'PCPSARE1', 'PSATEST1', 'PSATIME', 'PCPSARS1', 'PCPSADE1', 'PCDMDECN', 'SCNTMNY1', 'SCNTMEL1', 'SCNTPAID', 'SCNTWRK1', 'SCNTLPAD', 'SCNTLWK1', 'SXORIENT', 'TRNSGNDR', 'RCSGENDR', 'RCSRLTN2', 'CASTHDX2', 'CASTHNO2', 'EMTSUPRT', 'LSATISFY', 'ADPLEASR', 'ADDOWN', 'ADSLEEP', 'ADENERGY', 'ADEAT1', 'ADFAIL', 'ADTHINK', 'ADMOVE', 'MISTMNT', 'ADANXEV', 'MSCODE', '_CHISPNC', '_CRACE1', '_CPRACE', '_CLLCPWT', '_DUALCOR', 'METVL11_', 'METVL21_', 'ACTIN11_', 'ACTIN21_', 'PADUR1_', 'PADUR2_', 'PAFREQ1_', 'PAFREQ2_', '_MINAC11', '_MINAC21', 'PAMIN11_', 'PAMIN21_', 'PA1MIN_', 'PAVIG11_', 'PAVIG21_', 'PA1VIGM_', '_FLSHOT6', '_PNEUMO2', 'GENHLTH_7.0_encoded', 'GENHLTH_9.0_encoded', 'HLTHPLN1_7.0_encoded', 'HLTHPLN1_9.0_encoded', 'PERSDOC2_7.0_encoded', 'PERSDOC2_9.0_encoded', 'MEDCOST_7.0_encoded', 'MEDCOST_9.0_encoded', 'CHECKUP1_8.0_encoded', 'CHECKUP1_9.0_encoded', 'BPHIGH4_2.0_encoded', 'BPHIGH4_4.0_encoded', 'BPHIGH4_7.0_encoded', 'BPHIGH4_9.0_encoded', 'BLOODCHO_9.0_encoded', 'CHOLCHK_9.0_encoded', 'TOLDHI2_7.0_encoded', 'TOLDHI2_9.0_encoded', 'CVDSTRK3_7.0_encoded', 'CVDSTRK3_9.0_encoded', 'ASTHMA3_7.0_encoded', 'ASTHMA3_9.0_encoded', 'CHCSCNCR_7.0_encoded', 'CHCSCNCR_9.0_encoded', 'CHCOCNCR_7.0_encoded', 'CHCOCNCR_9.0_encoded', 'CHCCOPD1_7.0_encoded', 'CHCCOPD1_9.0_encoded', 'HAVARTH3_7.0_encoded', 'HAVARTH3_9.0_encoded', 'ADDEPEV2_7.0_encoded', 'ADDEPEV2_9.0_encoded', 'CHCKIDNY_7.0_encoded', 'CHCKIDNY_9.0_encoded', 'DIABETE3_2.0_encoded', 'DIABETE3_7.0_encoded', 'DIABETE3_9.0_encoded', 'MARITAL_9.0_encoded', 'EDUCA_1.0_encoded', 'EDUCA_9.0_encoded', 'RENTHOM1_7.0_encoded', 'RENTHOM1_9.0_encoded', 'VETERAN3_7.0_encoded', 'VETERAN3_9.0_encoded', 'EMPLOY1_9.0_encoded', 'INTERNET_7.0_encoded', 'INTERNET_9.0_encoded', 'QLACTLM2_7.0_encoded', 'QLACTLM2_9.0_encoded', 'USEEQUIP_7.0_encoded', 'USEEQUIP_9.0_encoded', 'BLIND_7.0_encoded', 'BLIND_9.0_encoded', 'DECIDE_7.0_encoded', 'DECIDE_9.0_encoded', 'DIFFWALK_7.0_encoded', 'DIFFWALK_9.0_encoded', 'DIFFDRES_7.0_encoded', 'DIFFDRES_9.0_encoded', 'DIFFALON_7.0_encoded', 'DIFFALON_9.0_encoded', 'SMOKE100_7.0_encoded', 'SMOKE100_9.0_encoded', 'USENOW3_7.0_encoded', 'USENOW3_9.0_encoded', 'EXERANY2_7.0_encoded', 'EXERANY2_9.0_encoded', 'SEATBELT_7.0_encoded', 'SEATBELT_8.0_encoded', 'SEATBELT_9.0_encoded', 'FLUSHOT6_7.0_encoded', 'FLUSHOT6_9.0_encoded', 'PNEUVAC3_9.0_encoded', 'HIVTST6_9.0_encoded', 'QSTVER_13.0_encoded', 'QSTLANG_3.0_encoded', '_RFHLTH_9.0_encoded', '_RFHYPE5_9.0_encoded', '_RFCHOL_9.0_encoded', '_LTASTH1_9.0_encoded', '_CASTHM1_9.0_encoded', '_ASTHMS1_9.0_encoded', '_PRACE1_5.0_encoded', '_PRACE1_7.0_encoded', '_PRACE1_8.0_encoded', '_PRACE1_77.0_encoded', '_MRACE1_5.0_encoded', '_MRACE1_77.0_encoded', '_HISPANC_9.0_encoded', '_RACE_5.0_encoded', '_RACE_6.0_encoded', '_CHLDCNT_6.0_encoded', '_CHLDCNT_9.0_encoded', '_EDUCAG_9.0_encoded', 'DRNKANY5_7.0_encoded', '_MISVEGN_2.0_encoded', '_MISVEGN_3.0_encoded', '_FRT16', '_VEG23', '_FRUITEX_2.0_encoded', '_VEGETEX_2.0_encoded', '_STATE', 'FMONTH', 'IDATE', 'IMONTH', 'IDAY', 'IYEAR_2015.0_encoded', 'IYEAR_2016.0_encoded', 'DISPCODE_1100.0_encoded', 'DISPCODE_1200.0_encoded', 'GENHLTH_3.0_encoded', 'MENTHLTH', 'HLTHPLN1_1.0_encoded', 'HLTHPLN1_2.0_encoded', 'PERSDOC2_1.0_encoded', 'MEDCOST_1.0_encoded', 'MEDCOST_2.0_encoded', 'CHECKUP1_2.0_encoded', 'CHECKUP1_3.0_encoded', 'CHECKUP1_4.0_encoded', 'CHECKUP1_7.0_encoded', 'BLOODCHO_7.0_encoded', 'CHOLCHK_4.0_encoded', 'CHOLCHK_7.0_encoded', 'ASTHMA3_1.0_encoded', 'DIABETE3_4.0_encoded', 'MARITAL_1.0_encoded', 'MARITAL_2.0_encoded', 'MARITAL_4.0_encoded', 'MARITAL_6.0_encoded', 'EDUCA_2.0_encoded', 'EDUCA_3.0_encoded', 'EDUCA_4.0_encoded', 'EDUCA_5.0_encoded', 'RENTHOM1_1.0_encoded', 'RENTHOM1_2.0_encoded', 'RENTHOM1_3.0_encoded', 'EMPLOY1_2.0_encoded', 'EMPLOY1_3.0_encoded', 'EMPLOY1_4.0_encoded', 'EMPLOY1_5.0_encoded', 'EMPLOY1_6.0_encoded', 'INCOME2_1.0_encoded', 'INCOME2_3.0_encoded', 'INCOME2_4.0_encoded', 'INCOME2_5.0_encoded', 'INCOME2_6.0_encoded', 'INCOME2_7.0_encoded', 'INCOME2_77.0_encoded', 'INCOME2_99.0_encoded', 'WEIGHT2', 'HEIGHT3', 'USENOW3_1.0_encoded', 'USENOW3_2.0_encoded', 'USENOW3_3.0_encoded', 'FRUITJU1', 'FRUIT1', 'FVBEANS', 'FVGREEN', 'FVORANG', 'VEGETAB1', 'SEATBELT_1.0_encoded', 'SEATBELT_2.0_encoded', 'SEATBELT_3.0_encoded', 'SEATBELT_4.0_encoded', 'SEATBELT_5.0_encoded', 'HIVTST6_1.0_encoded', 'HIVTST6_2.0_encoded', 'HIVTST6_7.0_encoded', 'QSTVER_11.0_encoded', 'QSTVER_12.0_encoded', 'QSTVER_20.0_encoded', 'QSTVER_21.0_encoded', 'QSTVER_22.0_encoded', 'QSTVER_23.0_encoded', 'QSTLANG_1.0_encoded', 'QSTLANG_2.0_encoded', '_STSTR', '_STRWT', '_RAWRAKE', '_WT2RAKE', '_DUALUSE_1.0_encoded', '_DUALUSE_2.0_encoded', '_DUALUSE_9.0_encoded', '_LLCPWT', '_HCVU651_2.0_encoded', '_CHOLCHK_2.0_encoded', '_CHOLCHK_9.0_encoded', '_LTASTH1_2.0_encoded', '_ASTHMS1_2.0_encoded', '_PRACE1_1.0_encoded', '_PRACE1_2.0_encoded', '_PRACE1_3.0_encoded', '_PRACE1_4.0_encoded', '_PRACE1_6.0_encoded', '_PRACE1_99.0_encoded', '_MRACE1_1.0_encoded', '_MRACE1_2.0_encoded', '_MRACE1_3.0_encoded', '_MRACE1_4.0_encoded', '_MRACE1_6.0_encoded', '_MRACE1_7.0_encoded', '_MRACE1_99.0_encoded', '_HISPANC_1.0_encoded', '_HISPANC_2.0_encoded', '_RACE_1.0_encoded', '_RACE_2.0_encoded', '_RACE_3.0_encoded', '_RACE_4.0_encoded', '_RACE_7.0_encoded', '_RACE_8.0_encoded', '_RACE_9.0_encoded', '_RACEG21_1.0_encoded', '_RACEG21_2.0_encoded', '_RACEG21_9.0_encoded', '_RACEGR3_1.0_encoded', '_RACEGR3_2.0_encoded', '_RACEGR3_3.0_encoded', '_RACEGR3_4.0_encoded', '_RACEGR3_5.0_encoded', '_RACEGR3_9.0_encoded', '_RACE_G1_1.0_encoded', '_RACE_G1_2.0_encoded', '_RACE_G1_3.0_encoded', '_RACE_G1_4.0_encoded', '_RACE_G1_5.0_encoded', '_AGE65YR_3.0_encoded', '_AGE_G_5.0_encoded', 'HTIN4', 'HTM4', '_BMI5CAT_1.0_encoded', '_BMI5CAT_2.0_encoded', '_BMI5CAT_3.0_encoded', '_RFBMI5_1.0_encoded', '_RFBMI5_9.0_encoded', '_CHLDCNT_4.0_encoded', '_CHLDCNT_5.0_encoded', '_EDUCAG_2.0_encoded', '_EDUCAG_3.0_encoded', '_INCOMG_3.0_encoded', '_INCOMG_4.0_encoded', '_INCOMG_9.0_encoded', '_SMOKER3_1.0_encoded', '_SMOKER3_2.0_encoded', '_SMOKER3_9.0_encoded', '_RFSMOK3_1.0_encoded', '_RFSMOK3_2.0_encoded', '_RFSMOK3_9.0_encoded', 'DRNKANY5_9.0_encoded', 'DROCDY3_', '_RFBING5_9.0_encoded', '_DRNKWEK', '_RFDRHV5_1.0_encoded', '_RFDRHV5_2.0_encoded', '_RFDRHV5_9.0_encoded', 'FTJUDA1_', 'FRUTDA1_', 'BEANDAY_', 'GRENDAY_', 'ORNGDAY_', 'VEGEDA1_', '_MISFRTN_0.0_encoded', '_MISFRTN_1.0_encoded', '_MISFRTN_2.0_encoded', '_MISVEGN_0.0_encoded', '_MISVEGN_1.0_encoded', '_MISVEGN_4.0_encoded', '_FRTRESP', '_VEGRESP', '_FRUTSUM', '_VEGESUM', '_FRTLT1_1.0_encoded', '_FRTLT1_2.0_encoded', '_FRTLT1_9.0_encoded', '_VEGLT1_1.0_encoded', '_VEGLT1_2.0_encoded', '_VEGLT1_9.0_encoded', '_FRUITEX_0.0_encoded', '_FRUITEX_1.0_encoded', '_VEGETEX_0.0_encoded', '_VEGETEX_1.0_encoded', '_TOTINDA_9.0_encoded', 'MAXVO2_', 'FC60_', 'STRFREQ_', 'PAMISS1__0.0_encoded', 'PAMISS1__1.0_encoded', 'PAMISS1__9.0_encoded', '_PACAT1_1.0_encoded', '_PACAT1_2.0_encoded', '_PACAT1_3.0_encoded', '_PACAT1_9.0_encoded', '_PAINDX1_1.0_encoded', '_PAINDX1_2.0_encoded', '_PAINDX1_9.0_encoded', '_PA150R2_1.0_encoded', '_PA150R2_2.0_encoded', '_PA150R2_9.0_encoded', '_PA300R2_1.0_encoded', '_PA300R2_9.0_encoded', '_PA30021_1.0_encoded', '_PA30021_2.0_encoded', '_PA30021_9.0_encoded', '_PASTRNG_1.0_encoded', '_PASTRNG_2.0_encoded', '_PASTRNG_9.0_encoded', '_PAREC1_1.0_encoded', '_PAREC1_2.0_encoded', '_PAREC1_3.0_encoded', '_PAREC1_4.0_encoded', '_PAREC1_9.0_encoded', '_PASTAE1_1.0_encoded', '_PASTAE1_2.0_encoded', '_PASTAE1_9.0_encoded', '_LMTACT1_9.0_encoded', '_LMTSCL1_9.0_encoded', '_RFSEAT2_1.0_encoded', '_RFSEAT2_2.0_encoded', '_RFSEAT2_9.0_encoded', '_RFSEAT3_1.0_encoded', '_RFSEAT3_2.0_encoded', '_RFSEAT3_9.0_encoded', '_AIDTST3_1.0_encoded', '_AIDTST3_2.0_encoded', '_AIDTST3_9.0_encoded']\n"
     ]
    }
   ],
   "source": [
    "removed_features = removed_missing_values + removed_variance + removed_correlation\n",
    "print(removed_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\utilisateur\\AppData\\Local\\Temp\\ipykernel_17564\\3861114181.py:15: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  df_conserved.to_excel(output_file_path, index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file generated and saved as conserved_features_output.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your Excel file with all features and their meanings\n",
    "input_file_path = 'BRFSS_2015_Cleaned_Parameters_excel.xlsx'\n",
    "df_parameters = pd.read_excel(input_file_path)\n",
    "\n",
    "# List of conserved features to filter\n",
    "conserved_features = x_train_headers\n",
    "\n",
    "# Filter the DataFrame for conserved features\n",
    "df_conserved = df_parameters[df_parameters['Parameter'].isin(conserved_features)]\n",
    "\n",
    "# Save the filtered data to a new Excel file\n",
    "output_file_path = 'conserved_features_output.xlsx'\n",
    "df_conserved.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"Excel file generated and saved as {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file generated and saved as removed_features_with_description_log.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\utilisateur\\AppData\\Local\\Temp\\ipykernel_17564\\2870947207.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_removed_info['Reason of Removal'] = df_removed_info['Parameter'].map(dict(zip(removed_features_, removal_reasons)))\n",
      "C:\\Users\\utilisateur\\AppData\\Local\\Temp\\ipykernel_17564\\2870947207.py:18: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  df_removed_info.to_excel(output_file_path, index=False)\n"
     ]
    }
   ],
   "source": [
    "# Parse the removal log into a structured format\n",
    "removed_features_ = []\n",
    "removal_reasons = []\n",
    "\n",
    "for log in removal_log:\n",
    "    feature, reason = log.split(\" removed at \")[0], log.split(\": \", 1)[1]\n",
    "    removed_features_.append(feature)\n",
    "    removal_reasons.append(reason)\n",
    "\n",
    "# Filter the DataFrame to include only the removed features\n",
    "df_removed_info = df_parameters[df_parameters['Parameter'].isin(removed_features_)]\n",
    "\n",
    "# Add the reason for removal to the DataFrame\n",
    "df_removed_info['Reason of Removal'] = df_removed_info['Parameter'].map(dict(zip(removed_features_, removal_reasons)))\n",
    "\n",
    "# Save the updated DataFrame with feature names, descriptions, value meanings, and reasons for removal to an Excel file\n",
    "output_file_path = 'removed_features_with_description_log.xlsx'\n",
    "df_removed_info.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"Excel file generated and saved as {output_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
